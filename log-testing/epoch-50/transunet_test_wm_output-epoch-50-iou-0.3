Model loaded from research/white-mold-applications/model/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/epoch_49.pth
Namespace(volume_path='/home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image', dataset='WhiteMold', num_classes=8, list_dir='', max_iterations=20000, max_epochs=50, batch_size=24, img_size=224, is_savenii=True, n_skip=3, vit_name='R50-ViT-B_16', test_save_dir='research/white-mold-applications/model/predictions', deterministic=1, base_lr=0.01, seed=1234, vit_patches_size=16, Dataset=<class 'datasets_tun.dataset_white_mold.WhiteMold_dataset'>, z_spacing=1, is_pretrain=True, exp='TU_WhiteMold224')
TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224
arg.is_savenii: True - before inference
arg.is_savenii: True - if true
model: VisionTransformer(
  (transformer): Transformer(
    (embeddings): Embeddings(
      (hybrid_model): ResNetV2(
        (root): Sequential(
          (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
          (gn): GroupNorm(32, 64, eps=1e-06, affine=True)
          (relu): ReLU(inplace=True)
        )
        (body): Sequential(
          (block1): Sequential(
            (unit1): PreActBottleneck(
              (gn1): GroupNorm(32, 64, eps=1e-06, affine=True)
              (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 64, eps=1e-06, affine=True)
              (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
              (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn_proj): GroupNorm(256, 256, eps=1e-05, affine=True)
            )
            (unit2): PreActBottleneck(
              (gn1): GroupNorm(32, 64, eps=1e-06, affine=True)
              (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 64, eps=1e-06, affine=True)
              (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit3): PreActBottleneck(
              (gn1): GroupNorm(32, 64, eps=1e-06, affine=True)
              (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 64, eps=1e-06, affine=True)
              (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
          )
          (block2): Sequential(
            (unit1): PreActBottleneck(
              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
              (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (gn_proj): GroupNorm(512, 512, eps=1e-05, affine=True)
            )
            (unit2): PreActBottleneck(
              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit3): PreActBottleneck(
              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit4): PreActBottleneck(
              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
          )
          (block3): Sequential(
            (unit1): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
              (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (gn_proj): GroupNorm(1024, 1024, eps=1e-05, affine=True)
            )
            (unit2): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit3): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit4): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit5): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit6): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit7): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit8): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
            (unit9): PreActBottleneck(
              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)
              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (relu): ReLU(inplace=True)
            )
          )
        )
      )
      (patch_embeddings): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): Encoder(
      (layer): ModuleList(
        (0-11): 12 x Block(
          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (ffn): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (attn): Attention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (out): Linear(in_features=768, out_features=768, bias=True)
            (attn_dropout): Dropout(p=0.0, inplace=False)
            (proj_dropout): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
        )
      )
      (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    )
  )
  (decoder): DecoderCup(
    (conv_more): Conv2dReLU(
      (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (blocks): ModuleList(
      (0): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (up): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')
      )
      (1): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (up): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')
      )
      (2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (up): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')
      )
      (3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (up): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')
      )
    )
  )
  (segmentation_head): SegmentationHead(
    (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Identity()
  )
)
test_save_path: research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224

Showing Model size

=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
VisionTransformer                                       [1, 8, 224, 224]          --
├─Transformer: 1-1                                      [1, 196, 768]             --
│    └─Embeddings: 2-1                                  [1, 196, 768]             150,528
│    │    └─ResNetV2: 3-1                               [1, 1024, 14, 14]         11,894,848
│    │    └─Conv2d: 3-2                                 [1, 768, 14, 14]          787,200
│    │    └─Dropout: 3-3                                [1, 196, 768]             --
│    └─Encoder: 2-2                                     [1, 196, 768]             --
│    │    └─ModuleList: 3-4                             --                        85,054,464
│    │    └─LayerNorm: 3-5                              [1, 196, 768]             1,536
├─DecoderCup: 1-2                                       [1, 16, 224, 224]         --
│    └─Conv2dReLU: 2-3                                  [1, 512, 14, 14]          --
│    │    └─Conv2d: 3-6                                 [1, 512, 14, 14]          3,538,944
│    │    └─BatchNorm2d: 3-7                            [1, 512, 14, 14]          1,024
│    │    └─ReLU: 3-8                                   [1, 512, 14, 14]          --
│    └─ModuleList: 2-4                                  --                        --
│    │    └─DecoderBlock: 3-9                           [1, 256, 28, 28]          2,950,144
│    │    └─DecoderBlock: 3-10                          [1, 128, 56, 56]          737,792
│    │    └─DecoderBlock: 3-11                          [1, 64, 112, 112]         147,712
│    │    └─DecoderBlock: 3-12                          [1, 16, 224, 224]         11,584
├─SegmentationHead: 1-3                                 [1, 8, 224, 224]          --
│    └─Conv2d: 2-5                                      [1, 8, 224, 224]          1,160
│    └─Identity: 2-6                                    [1, 8, 224, 224]          --
=========================================================================================================
Total params: 105,276,936
Trainable params: 105,276,936
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 11.95
=========================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 416.34
Params size (MB): 420.51
Estimated Total Size (MB): 837.45
=========================================================================================================

GFLOPS: 25.41 GMac, Parameters: 105.28 M

test_image_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test

class WhiteMold_dataset, constructor called
class WhiteMold_dataset, base_dir: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image
class WhiteMold_dataset, list_dir: 
class WhiteMold_dataset, split: test
class WhiteMold_dataset, transform: None
323 test iterations per epoch
323 test iterations per epoch
tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[135, 131, 165, 168]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165]), array([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 137, 165, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[135, 131, 165, 168]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[135, 137, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785691.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 1

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[109, 106, 191, 193]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([108, 108, 108, ..., 192, 192, 192]), array([165, 166, 167, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[108, 108, 191, 192]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[109, 106, 191, 193]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[108, 108, 191, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1500526739.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 2

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[106, 112, 193, 188]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 193, 193, 193]), array([119, 120, 121, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[110, 110, 189, 193]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[106, 112, 193, 188]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[110, 110, 189, 193]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3979-bbox-1533656590.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 3

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[141, 138, 158, 161]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[141, 138, 158, 161]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797254.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 4

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[116,  81, 184, 218]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 86,  86,  86, ..., 212, 212, 212]), array([173, 174, 175, ..., 140, 141, 142]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 99,  86, 208, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[116,  81, 184, 218]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 99,  86, 208, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212058.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 5

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[129, 133, 170, 167]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 174, 174, 174]), array([146, 147, 148, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 126, 174, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[129, 133, 170, 167]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[126, 126, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533752.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 6

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 99, 123, 201, 177]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 176, 176, 176]), array([151, 152, 153, ..., 127, 128, 129]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[107, 123, 193, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 99, 123, 201, 177]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[107, 123, 193, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434568.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 7

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[118, 120, 181, 179]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([111, 111, 111, ..., 199, 199, 199]), array([122, 123, 124, ..., 135, 136, 137]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112, 111, 185, 199]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[118, 120, 181, 179]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[112, 111, 185, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332475.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 8

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[130, 121, 170, 178]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 180, 180, 180]), array([133, 134, 135, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 119, 177, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[130, 121, 170, 178]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[118, 119, 177, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135678.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 9

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 91,  75, 208, 225]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 74,  74,  74, ..., 229, 229, 229]), array([106, 107, 108, ..., 123, 124, 125]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 86,  74, 219, 229]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 91,  75, 208, 225]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 86,  74, 219, 229]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947686.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 10

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[130, 129, 170, 170]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, ..., 169, 169, 169]), array([141, 142, 143, ..., 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 134, 166, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[130, 129, 170, 170]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[130, 134, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748029.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 11

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[117, 124, 182, 175]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 176, 176, 176]), array([134, 135, 136, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 127, 176, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[117, 124, 182, 175]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[118, 127, 176, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610356.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 12

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[141, 137, 159, 162]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 191, 191, 191]), array([115, 116, 117, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 79, 115, 192, 191]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[141, 137, 159, 162]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 79, 115, 192, 191]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797053.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 13

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[116, 119, 183, 180]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 178, 178, 178]), array([163, 164, 165, ..., 150, 151, 152]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 122, 183, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[116, 119, 183, 180]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 122, 183, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211850.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 14

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[140, 136, 159, 164]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 178, 178, 178]), array([154, 155, 156, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 121, 183, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[140, 136, 159, 164]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 121, 183, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796994.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 15

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[120, 129, 179, 170]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([102, 102, 102, ..., 181, 181, 181]), array([162, 163, 164, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[104, 102, 192, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[120, 129, 179, 170]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[104, 102, 192, 181]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818813.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 16

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[120, 113, 180, 187]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 188, 188, 188]), array([134, 135, 136, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[116, 110, 181, 188]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[120, 113, 180, 187]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[116, 110, 181, 188]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930897.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 17

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[122,  96, 178, 203]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 185, 185, 185]), array([138, 139, 140, ..., 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 121, 169, 185]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[122,  96, 178, 203]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[126, 121, 169, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096986.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 18

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 79, 138, 153, 202]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 94,  94,  94, ..., 207, 207, 207]), array([178, 179, 180, ..., 186, 187, 188]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 80,  94, 212, 207]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 79, 138, 153, 202]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 80,  94, 212, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-02-fazenda-vs-pivo-06-IMG_2875-bbox-1529999100.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 19

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[114, 106, 186, 194]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([100, 100, 100, ..., 195, 195, 195]), array([138, 139, 140, ..., 135, 136, 137]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 100, 185, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[114, 106, 186, 194]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[115, 100, 185, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212091.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 20

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[122, 118, 178, 182]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 176, 176, 176]), array([135, 136, 137, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 125, 174, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[122, 118, 178, 182]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[125, 125, 174, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-03-pivo-03-20230930_123113-bbox-1429245310.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 21

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[ 98,  99, 202, 201]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([102, 102, 102, ..., 201, 201, 201]), array([170, 171, 172, ..., 183, 184, 185]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 102, 195, 201]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[ 98,  99, 202, 201]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[ 96, 102, 195, 201]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604248.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 22

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 134, 163, 166]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 137, 162, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 134, 163, 166]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[135, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161557-bbox-1415718287.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 23

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 131, 171, 169]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 168, 168, 168]), array([137, 138, 139, ..., 159, 160, 161]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 131, 169, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[129, 131, 171, 169]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[131, 131, 169, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775271.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 24

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 135, 164, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 135, 164, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 135, 164, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[135, 135, 164, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776103.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 25

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[129, 120, 170, 180]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 144,
       144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
       166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
       166, 166, 166, 166, 166, 167, 167, 167, 167, 167, 167, 167, 167,
       167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167,
       167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 168, 168,
       168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168,
       168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168,
       168, 168, 168, 168, 169, 169, 169, 169, 169, 169, 169, 169, 169,
       169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169,
       169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 170,
       170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170,
       170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170,
       170, 170, 170, 170, 170, 171, 171, 171, 171, 171, 171, 171, 171,
       171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,
       171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 172,
       172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172,
       172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172,
       172, 172, 172, 172, 172, 172, 173, 173, 173, 173, 173, 173, 173,
       173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173,
       173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 174, 174,
       174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174,
       174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174,
       174, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,
       175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175,
       175, 175, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176,
       176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176,
       176, 176, 176, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,
       177, 177, 177, 177, 177, 177, 177, 177, 177]), array([146, 147, 148, 149, 145, 146, 147, 148, 149, 150, 151, 152, 145,
       146, 147, 148, 149, 150, 151, 152, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,
       167, 168, 169, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 166, 167, 168, 169, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 166, 167, 168, 169, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,
       167, 168, 169, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 166, 167, 168, 169, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 166, 167, 168, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 166, 167, 168, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 166, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 166, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 169, 170, 170]), array([146, 147, 148, ..., 134, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 142, 169, 177],
        [130, 125, 170, 170]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([3, 5])
new_targets: [{'boxes': tensor([[129, 120, 170, 180]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[134, 142, 169, 177],
        [130, 125, 170, 170]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533791.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 26

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[123, 119, 176, 180]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 183, 183, 183]), array([131, 132, 133, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 125, 176, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[123, 119, 176, 180]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[123, 125, 176, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013908.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 27

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[122, 123, 177, 177]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 174, 174, 174]), array([131, 132, 133, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 125, 176, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[122, 123, 177, 177]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[123, 125, 176, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160508-bbox-1411007689.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 28

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[132, 129, 168, 170]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 173, 173, 173]), array([137, 138, 139, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 127, 173, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[132, 129, 168, 170]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[129, 127, 173, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120312-bbox-1533675660.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 29

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[121, 128, 179, 171]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 173, 173, 173]), array([131, 132, 133, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 126, 174, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[121, 128, 179, 171]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[122, 126, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4519-bbox-1533833204.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 30

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[126, 115, 174, 184]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 176, 176, 177]), array([139, 140, 141, ..., 163, 164, 157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 126, 170, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[126, 115, 174, 184]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 126, 170, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675469.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 31

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 93,  97, 206, 203]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 84,  84,  84, ..., 212, 212, 212]), array([102, 103, 104, ..., 111, 112, 113]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 94,  84, 209, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 93,  97, 206, 203]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 94,  84, 209, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679961.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 32

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[110,  99, 190, 201]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([112, 112, 112, ..., 191, 191, 191]), array([121, 122, 123, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[104, 112, 193, 191]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[110,  99, 190, 201]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[104, 112, 193, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451613.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 33

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 92,  76, 207, 224]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 68,  68,  68, ..., 231, 231, 231]), array([104, 105, 106, ..., 131, 132, 133]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 83,  68, 212, 231]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 92,  76, 207, 224]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 83,  68, 212, 231]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2530-bbox-1505679998.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 34

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[126, 119, 174, 180]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 178, 178, 178]), array([149, 150, 151, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 125, 174, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[126, 119, 174, 180]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[126, 125, 174, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675467.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 35

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[104, 114, 195, 185]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([108, 108, 108, ..., 192, 192, 192]), array([170, 171, 172, ..., 131, 132, 133]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[104, 108, 203, 192]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[104, 114, 195, 185]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[104, 108, 203, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2528-bbox-1505667180.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 36

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[130, 103, 170, 197]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 180, 180, 180]), array([143, 144, 145, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 126, 178, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[130, 103, 170, 197]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[129, 126, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078097.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 37

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[116, 122, 184, 177]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 181, 181, 181]), array([162, 163, 164, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 119, 184, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[116, 122, 184, 177]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[118, 119, 184, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1804-bbox-1524227328.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 38

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[112, 121, 187, 178]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 176, 176, 176]), array([135, 136, 137, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 129, 176, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[112, 121, 187, 178]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[123, 129, 176, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930918.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 39

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[123,  90, 177, 210]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 192, 192, 192]), array([150, 151, 152, ..., 146, 147, 148]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 126, 170, 192]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[123,  90, 177, 210]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[126, 126, 170, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743250.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 40

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[126, 133, 173, 166]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 169, 169, 169]), array([137, 138, 139, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 130, 169, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[126, 133, 173, 166]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 130, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013917.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 41

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[135, 135, 165, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 166, 166, 166,
       166]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 147, 148, 149,
       150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 135, 164, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[135, 135, 165, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[134, 135, 164, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092113-bbox-1418087509.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 42

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[138, 132, 161, 167]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136,
       136, 136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161]), array([146, 147, 148, 149, 150, 151, 152, 153, 146, 147, 148, 149, 150,
       151, 152, 153, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 135, 160, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[138, 132, 161, 167]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[137, 135, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2798-bbox-1531448008.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 43

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[131, 138, 154, 161]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 168, 168, 168]), array([138, 139, 140, ..., 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 131, 164, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[131, 138, 154, 161]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 131, 164, 168]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445789.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 44

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[126, 116, 174, 184]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 191, 191, 191]), array([153, 154, 155, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 116, 178, 191]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[126, 116, 174, 184]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[125, 116, 178, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610377.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 45

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[122, 124, 178, 176]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 170, 170, 170]), array([153, 154, 155, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 127, 172, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[122, 124, 178, 176]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[126, 127, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785699.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 46

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[124, 124, 175, 176]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 172, 172, 172]), array([159, 160, 161, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 125, 174, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[124, 124, 175, 176]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[125, 125, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_162248-bbox-1416067564.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 47

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[104, 109, 196, 190]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 193, 193, 193]), array([170, 171, 172, ..., 190, 191, 192]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[100, 106, 199, 193]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[104, 109, 196, 190]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[100, 106, 199, 193]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604258.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 48

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[104,  88, 196, 212]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 94,  94,  94, ..., 209, 209, 209]), array([110, 111, 112, ..., 142, 143, 144]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 82,  94, 219, 209]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[104,  88, 196, 212]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 82,  94, 219, 209]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_163521-bbox-1529526422.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 49

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[139, 137, 161, 162]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161]), array([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 137, 162, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[139, 137, 161, 162]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 137, 162, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_135337-bbox-1407347421.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 50

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[130, 127, 170, 173]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 176, 176, 176]), array([139, 140, 141, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 127, 170, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[130, 127, 170, 173]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[129, 127, 170, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015009.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 51

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 65,  68, 234, 231]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 70,  70,  70, ..., 229, 229, 229]), array([ 75,  76,  77, ..., 205, 206, 207]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 55,  70, 233, 229]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 65,  68, 234, 231]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 55,  70, 233, 229]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105404.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 52

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[112, 114, 187, 185]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 185, 185, 185]), array([173, 174, 175, ..., 135, 136, 137]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[108, 110, 188, 185]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[112, 114, 187, 185]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[108, 110, 188, 185]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434579.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 53

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[133, 134, 166, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165]), array([142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 134, 165, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[133, 134, 166, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014504.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 54

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[100,  94, 200, 206]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 189, 189, 189]), array([170, 171, 172, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112, 110, 187, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[100,  94, 200, 206]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[112, 110, 187, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947677.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 55

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[207, 121, 266, 178]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 169, 169, 169]), array([130, 131, 132, ..., 155, 156, 157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 129, 169, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[207, 121, 266, 178]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[115, 129, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776168.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 56

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[129, 130, 170, 169]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 170, 170, 170]), array([139, 140, 141, ..., 155, 156, 157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 130, 169, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[129, 130, 170, 169]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[129, 130, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524765.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 57

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[107, 105, 192, 194]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 94,  94,  94, ..., 199, 199, 199]), array([141, 142, 143, ..., 124, 125, 126]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[107,  94, 201, 199]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[107, 105, 192, 194]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[107,  94, 201, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001608.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 58

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[101, 112, 199, 187]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 203, 203, 203]), array([110, 111, 112, ..., 147, 148, 149]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 106, 207, 203]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[101, 112, 199, 187]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 96, 106, 207, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2477-bbox-1503748285.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 59

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[138, 138, 161, 162]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 152,
       152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 154, 154,
       154, 154, 154]), array([146, 147, 148, 149, 150, 146, 147, 148, 149, 150, 151, 152, 146,
       147, 148, 149, 150, 151, 152, 146, 147, 148, 149, 150, 146, 147,
       148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[146, 150, 152, 154]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[138, 138, 161, 162]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[146, 150, 152, 154]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1897-bbox-1519483072.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 60

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[122, 126, 178, 173]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([139, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158,
       158, 158, 158, 158, 158, 158]), array([142, 142, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 142, 143,
       144, 145, 146, 147, 148, 149]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 139, 153, 158]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[122, 126, 178, 173]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[137, 139, 153, 158]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527536645.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 61

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[140, 140, 159, 160]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       161, 161, 161]), array([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       147, 148, 149]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 138, 160, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[140, 140, 159, 160]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[138, 138, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112354-bbox-1417775833.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 62

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 136, 163, 164]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 137, 162, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 136, 163, 164]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[135, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012704.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 63

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[125, 127, 175, 173]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 188, 188, 188]), array([130, 131, 132, ..., 174, 175, 176]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 116, 185, 188]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[125, 127, 175, 173]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 116, 185, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524443.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 64

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 97, 102, 202, 198]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 183, 183, 183]), array([170, 171, 172, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[100, 115, 193, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 97, 102, 202, 198]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[100, 115, 193, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947725.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 65

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[100, 130, 200, 170]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 187, 187, 187]), array([107, 108, 109, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[100, 110, 196, 187]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[100, 130, 200, 170]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[100, 110, 196, 187]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-02-fazenda-vs-pivo-06-IMG_2875-bbox-1529999102.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 66

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[130, 132, 169, 168]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 170, 170, 170]), array([146, 147, 148, ..., 159, 160, 161]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 129, 170, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[130, 132, 169, 168]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[129, 129, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478590.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 67

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[127, 128, 172, 171]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 183, 183, 183]), array([174, 175, 176, ..., 172, 173, 174]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95, 115, 197, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[127, 128, 172, 171]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 95, 115, 197, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748053.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 68

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[138, 137, 162, 162]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       161, 161, 161, 161, 161, 161, 161]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       146, 147, 148, 149, 150, 151, 152]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 138, 161, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[138, 137, 162, 162]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014510.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 69

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 130, 170, 169]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 168, 168, 168]), array([139, 140, 141, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 129, 169, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[129, 130, 170, 169]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 129, 169, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348197.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 70

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 74,  63, 226, 236]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 64,  64,  64, ..., 239, 239, 239]), array([197, 198, 199, ..., 143, 144, 145]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 68,  64, 228, 239]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 74,  63, 226, 236]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 68,  64, 228, 239]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3928-bbox-1531429137.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 71

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[126, 103, 174, 196]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 180, 180, 180]), array([133, 134, 135, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 122, 174, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[126, 103, 174, 196]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[125, 122, 174, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227985.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 72

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[100, 106, 199, 193]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 197, 197, 197]), array([110, 111, 112, ..., 119, 120, 121]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 106, 205, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[100, 106, 199, 193]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 96, 106, 205, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652326.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 73

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[137, 138, 163, 161]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[137, 138, 163, 161]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_111804-bbox-1416831265.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 74

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[115,  94, 184, 205]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 201, 201, 201]), array([123, 124, 125, ..., 130, 131, 132]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112,  96, 184, 201]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[115,  94, 184, 205]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[112,  96, 184, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2482-bbox-1504140817.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 75

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[119, 115, 181, 184]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([118, 118, 118, ..., 180, 180, 180]), array([163, 164, 165, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[114, 118, 181, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[119, 115, 181, 184]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[114, 118, 181, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001614.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 76

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[124, 123, 176, 177]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 173, 173, 173]), array([155, 156, 157, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 125, 174, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[124, 123, 176, 177]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[125, 125, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013963.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 77

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 134, 163, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       162, 162, 162, 162, 162, 162, 162, 162]), array([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       146, 147, 148, 149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 137, 162, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 134, 163, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013875.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 78

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 99, 116, 200, 183]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([114, 114, 114, ..., 189, 189, 189]), array([100, 101, 102, ..., 190, 191, 192]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 79, 114, 215, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 99, 116, 200, 183]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 79, 114, 215, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451492.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 79

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[108,  92, 191, 208]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([100, 100, 100, ..., 189, 189, 189]), array([137, 138, 139, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[108, 100, 188, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[108,  92, 191, 208]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[108, 100, 188, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2562-bbox-1506386836.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 80

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[126, 130, 173, 170]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 170, 170, 170]), array([137, 138, 139, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 130, 169, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[126, 130, 173, 170]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[129, 130, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161627-bbox-1415718393.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 81

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[134, 130, 166, 170]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 134,
       134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 134, 134, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 166, 166, 166, 166, 166, 166, 166, 166, 166]), array([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 166, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 166, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 166, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       166, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 166, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 146, 147, 148, 149, 150, 151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 133, 166, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[134, 130, 166, 170]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[133, 133, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524795.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 82

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 133, 170, 167]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 136, 136, 136, 136, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162]), array([149, 150, 151, 152, 149, 150, 151, 152, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 131,
       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 131, 132, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 131, 132,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 131, 132, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 131, 132, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 131, 132, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 131, 132, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 131, 132, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 131, 132, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 135, 164, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[129, 133, 170, 167]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[131, 135, 164, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102985.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 83

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[132, 122, 168, 178]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 166, 166, 166, 166, 166,
       166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
       166, 166, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167,
       167, 167, 167, 167, 167, 168, 168, 168, 168, 168, 168, 168, 168,
       168, 168, 168, 168, 168, 168, 168, 168, 169, 169, 169, 169, 169,
       169]), array([141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 145, 146, 147, 148, 149,
       150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 135, 164, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[132, 122, 168, 178]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[134, 135, 164, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078086.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 84

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 94,  88, 205, 211]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([103, 103, 103, ..., 192, 192, 192]), array([162, 163, 164, ..., 172, 173, 174]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[103, 103, 197, 192]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 94,  88, 205, 211]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[103, 103, 197, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527544133.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 85

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[133, 131, 166, 168]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 168, 168, 168]), array([139, 140, 141, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 131, 166, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[133, 131, 166, 168]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 131, 166, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012707.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 86

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[114, 106, 186, 194]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 195, 195, 195]), array([121, 122, 123, ..., 128, 129, 130]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[106, 104, 191, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[114, 106, 186, 194]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[106, 104, 191, 195]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_162248-bbox-1416067575.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 87

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 66,  39, 233, 260]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 74,  74,  74, ..., 219, 219, 219]), array([184, 185, 186, ..., 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 79,  74, 224, 219]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 66,  39, 233, 260]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 79,  74, 224, 219]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500499785.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 88

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[ 85,  73, 214, 226]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([ 71,  71,  71, ..., 229, 229, 229]), array([ 98,  99, 100, ..., 207, 208, 209]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 70,  71, 225, 229]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[ 85,  73, 214, 226]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[ 70,  71, 225, 229]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604276.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 89

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 96,  82, 204, 218]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 84,  84,  84, ..., 225, 225, 225]), array([107, 108, 109, ..., 182, 183, 184]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 92,  84, 203, 225]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 96,  82, 204, 218]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 92,  84, 203, 225]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930921.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 90

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 98,  94, 201, 205]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 92,  92,  92, ..., 213, 213, 213]), array([110, 111, 112, ..., 190, 191, 192]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95,  92, 205, 213]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 98,  94, 201, 205]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 95,  92, 205, 213]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652330.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 91

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[ 85,  83, 214, 216]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([ 82,  82,  82, ..., 215, 215, 215]), array([104, 105, 106, ..., 202, 203, 204]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 86,  82, 216, 215]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[ 85,  83, 214, 216]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[ 86,  82, 216, 215]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_135136-bbox-1407347318.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 92

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[120, 125, 179, 174]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 177, 177, 177]), array([126, 127, 128, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 125, 180, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[120, 125, 179, 174]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[118, 125, 180, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135702.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 93

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[106, 113, 194, 187]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([102, 102, 103, ..., 203, 203, 203]), array([133, 134, 126, ..., 136, 137, 138]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[108, 102, 189, 203]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[106, 113, 194, 187]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[108, 102, 189, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743234.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 94

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 74, 109, 225, 191]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 70,  70,  70, ..., 219, 219, 219]), array([116, 117, 118, ..., 118, 119, 120]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 76,  70, 221, 219]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 74, 109, 225, 191]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 76,  70, 221, 219]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947984.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 95

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[113,  78, 186, 221]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 60,  60,  60, ..., 239, 239, 239]), array([126, 127, 128, ..., 185, 186, 187]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 94,  60, 208, 239]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[113,  78, 186, 221]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 94,  60, 208, 239]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500495896.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 96

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[132, 126, 168, 174]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 173, 173, 173]), array([149, 150, 151, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 123, 172, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[132, 126, 168, 174]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[126, 123, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434714.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 97

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[131, 132, 169, 167]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165]), array([142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 134, 165, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[131, 132, 169, 167]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775298.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 98

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 127, 173, 173]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 184, 184, 184]), array([121, 122, 123, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126,
       126, 126, 126, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
       127, 127, 127, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
       128, 128, 128, 133, 134, 135, 135, 136, 136, 137, 138, 139, 140,
       141]), array([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 173, 173, 173, 174, 173, 174, 174, 174, 174, 174,
       174]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[114, 127, 177, 184],
        [137, 126, 174, 141]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([1, 3])
new_targets: [{'boxes': tensor([[127, 127, 173, 173]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[114, 127, 177, 184],
        [137, 126, 174, 141]]), 'scores': tensor([1, 1]), 'labels': tensor([1, 3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818829.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 99

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 95, 108, 205, 191]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 189, 189, 189]), array([110, 111, 112, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 104, 195, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 95, 108, 205, 191]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 96, 104, 195, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530730668.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 100

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[134, 128, 165, 172]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 177, 177, 177]), array([137, 138, 139, ..., 142, 143, 144]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 125, 169, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[134, 128, 165, 172]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 125, 169, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797021.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 101

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[120, 122, 179, 177]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 174, 174, 174]), array([129, 130, 131, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 125, 174, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[120, 122, 179, 177]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[123, 125, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775232.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 102

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[102,  89, 198, 210]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 200, 200, 200]), array([123, 124, 125, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[111, 106, 193, 200]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[102,  89, 198, 210]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[111, 106, 193, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1967-bbox-1500168559.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 103

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[103, 116, 196, 184]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 193, 193, 193]), array([119, 120, 121, ..., 120, 121, 122]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[104, 107, 200, 193]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[103, 116, 196, 184]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[104, 107, 200, 193]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679959.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 104

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[119, 118, 181, 182]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 180, 180, 180]), array([130, 131, 132, ..., 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 122, 180, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[119, 118, 181, 182]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[123, 122, 180, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104752.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 105

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 84, 118, 215, 182]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 79,  79,  79, ..., 216, 216, 216]), array([122, 123, 124, ..., 189, 190, 191]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 82,  79, 215, 216]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 84, 118, 215, 182]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 82,  79, 215, 216]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530725274.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 106

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[122, 120, 177, 179]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([118, 118, 118, ..., 177, 177, 177]), array([133, 134, 135, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 118, 174, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[122, 120, 177, 179]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[123, 118, 174, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104720.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 107

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 97,  90, 202, 210]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 94,  94,  94, ..., 209, 209, 209]), array([177, 178, 179, ..., 124, 125, 126]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95,  94, 200, 209]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 97,  90, 202, 210]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 95,  94, 200, 209]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096983.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 108

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[114, 111, 186, 188]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 94,  94,  94, ..., 207, 207, 207]), array([153, 154, 155, ..., 179, 180, 181]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 94,  94, 204, 207]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[114, 111, 186, 188]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 94,  94, 204, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530731602.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 109

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[107, 112, 192, 188]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 76,  76,  76, ..., 231, 231, 231]), array([166, 167, 168, ..., 139, 140, 141]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[102,  76, 200, 231]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[107, 112, 192, 188]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[102,  76, 200, 231]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999543.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 110

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[127, 116, 172, 184]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 172, 172, 172]), array([142, 143, 144, ..., 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 119, 168, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[127, 116, 172, 184]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[131, 119, 168, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527535109.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 111

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[125, 117, 175, 183]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 180, 180, 180]), array([131, 132, 133, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 122, 178, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[125, 117, 175, 183]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[122, 122, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2478-bbox-1503748392.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 112

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[131, 133, 169, 167]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165]), array([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 134, 165, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[131, 133, 169, 167]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[134, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_110955-bbox-1416788230.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 113

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[106, 118, 193, 182]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 176, 176, 176]), array([123, 124, 125, ..., 123, 124, 125]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 99, 107, 191, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[106, 118, 193, 182]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 99, 107, 191, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104769.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 114

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 72, 100, 227, 200]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 91,  91,  91, ..., 208, 208, 208]), array([ 82,  83,  84, ..., 209, 210, 211]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 64,  91, 236, 208]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 72, 100, 227, 200]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 64,  91, 236, 208]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105411.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 115

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 56,  85, 244, 215]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 86,  86,  86, ..., 213, 213, 213]), array([139, 140, 141, ..., 209, 210, 211]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 66,  86, 233, 213]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 56,  85, 244, 215]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 66,  86, 233, 213]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3633-bbox-1506586882.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 116

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[113, 118, 186, 206]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 204, 204, 204]), array([121, 122, 123, ..., 128, 129, 130]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[108, 107, 189, 204]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[113, 118, 186, 206]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[108, 107, 189, 204]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604268.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 117

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[134, 135, 165, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 136, 136, 136, 136, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162]), array([147, 148, 149, 150, 147, 148, 149, 150, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 135, 162, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[134, 135, 165, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[135, 135, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013907.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 118

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 62,  78, 238, 221]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 66,  66,  66, ..., 221, 221, 221]), array([103, 104, 105, ..., 123, 124, 125]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 62,  66, 240, 221]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 62,  78, 238, 221]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 62,  66, 240, 221]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434827.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 119

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 130, 172, 169]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 169, 169, 169]), array([139, 140, 141, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 130, 170, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[127, 130, 172, 169]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 130, 170, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785712.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 120

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 75, 141,  91, 159]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[ 75, 141,  91, 159]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879143.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 121

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[111,  96, 189, 203]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 197, 197, 197]), array([166, 167, 168, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[111, 104, 188, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[111,  96, 189, 203]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[111, 104, 188, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_163521-bbox-1529526130.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 122

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[105, 104, 194, 195]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([111, 111, 111, ..., 180, 180, 180]), array([127, 128, 129, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[116, 111, 185, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[105, 104, 194, 195]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[116, 111, 185, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1967-bbox-1500168166.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 123

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[120, 113, 179, 187]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 200, 200, 200]), array([135, 136, 137, ..., 182, 183, 184]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[102, 107, 199, 200]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[120, 113, 179, 187]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[102, 107, 199, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999521.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 124

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[123, 102, 176, 197]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 134, 134, 134,
       134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 166, 166, 166,
       166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
       166, 166, 166, 166, 167, 167, 167, 167, 167, 167, 167, 167, 167,
       167, 167, 167, 167, 167, 167, 167, 167, 167, 168, 168, 168, 168,
       168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168,
       168, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169]), array([147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 166, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 166, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 166, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 166, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       166, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 166, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 166, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 166, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 166, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 166, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 133, 166, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[123, 102, 176, 197]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[137, 133, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540438.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 125

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 67,  92, 233, 208]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 90,  90,  90, ..., 215, 215, 215]), array([ 96,  97,  98, ..., 168, 169, 170]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 67,  90, 232, 215]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 67,  92, 233, 208]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 67,  90, 232, 215]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104735.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 126

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[120, 123, 180, 177]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 181, 181, 181]), array([126, 127, 128, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 116, 180, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[120, 123, 180, 177]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 116, 180, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135726.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 127

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 86, 107, 214, 192]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([102, 102, 102, ..., 196, 196, 196]), array([171, 172, 173, ..., 176, 177, 178]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95, 102, 199, 196]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 86, 107, 214, 192]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 95, 102, 199, 196]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3930-bbox-1531429402.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 128

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[116, 109, 183, 191]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 88,  88,  88, ..., 211, 211, 211]), array([100, 101, 102, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 79,  88, 223, 211]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[116, 109, 183, 191]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 79,  88, 223, 211]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_164849-bbox-1530658464.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 129

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[139, 141, 160, 158]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([149, 149, 149, 149, 150, 150, 150, 150, 151, 151, 151, 151, 152,
       152, 152, 152]), array([150, 151, 152, 153, 150, 151, 152, 153, 150, 151, 152, 153, 150,
       151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[150, 149, 153, 152]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[139, 141, 160, 158]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[150, 149, 153, 152]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2579-bbox-1499560953.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 130

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[123, 115, 176, 185]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 184, 184, 184]), array([153, 154, 155, ..., 168, 169, 170]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 115, 180, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[123, 115, 176, 185]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[122, 115, 180, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585146.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 131

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 62,  97, 238, 203]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 99,  99,  99, ..., 215, 215, 215]), array([125, 126, 127, ..., 172, 173, 174]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[100,  99, 209, 215]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 62,  97, 238, 203]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[100,  99, 209, 215]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105427.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 132

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 98, 111, 201, 188]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([111, 111, 111, ..., 189, 189, 189]), array([122, 123, 124, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[114, 111, 180, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 98, 111, 201, 188]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[114, 111, 180, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743231.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 133

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[129, 117, 170, 183]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([103, 103, 103, ..., 195, 195, 195]), array([119, 120, 121, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 103, 193, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[129, 117, 170, 183]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 96, 103, 193, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212093.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 134

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[140, 139, 159, 160]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154,
       154]), array([146, 147, 148, 149, 150, 151, 152, 153, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 145, 146, 147, 148, 149, 150, 151, 152, 153, 147, 148, 149,
       150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[142, 134, 157, 154]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[140, 139, 159, 160]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[142, 134, 157, 154]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534091011.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 135

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[114,  99, 186, 200]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 111, 111, ..., 191, 191, 191]), array([169, 139, 140, ..., 144, 145, 146]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 110, 184, 191]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[114,  99, 186, 200]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[119, 110, 184, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078092.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 136

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[132, 134, 167, 166]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, ..., 166, 166, 166]), array([145, 146, 147, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 133, 169, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[132, 134, 167, 166]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[131, 133, 169, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930912.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 137

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[124, 128, 176, 172]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 174, 174, 174]), array([155, 156, 157, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 126, 178, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[124, 128, 176, 172]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[122, 126, 178, 174]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2475-bbox-1503748166.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 138

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[130, 121, 169, 179]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 178, 178, 178]), array([131, 132, 133, ..., 147, 148, 149]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 119, 173, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[130, 121, 169, 179]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[118, 119, 173, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1884-bbox-1519001508.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 139

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[107,  85, 192, 215]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([100, 100, 100, ..., 207, 207, 207]), array([119, 120, 121, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[111, 100, 178, 207]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[107,  85, 192, 215]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[111, 100, 178, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999530.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 140

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[132, 131, 167, 168]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 168, 168, 168]), array([147, 148, 149, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 131, 168, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[132, 131, 167, 168]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 131, 168, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112354-bbox-1417775811.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 141

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[102,  97, 198, 202]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([102, 102, 102, ..., 199, 199, 199]), array([115, 116, 117, ..., 174, 175, 176]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 98, 102, 195, 199]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[102,  97, 198, 202]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 98, 102, 195, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2530-bbox-1505679995.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 142

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 73, 103, 226, 196]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 91,  91,  91, ..., 203, 203, 203]), array([167, 168, 169, ..., 195, 196, 197]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 78,  91, 215, 203]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 73, 103, 226, 196]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 78,  91, 215, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451419.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 143

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[110,  96, 189, 203]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 195, 195, 195]), array([123, 124, 125, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[114, 106, 181, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[110,  96, 189, 203]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[114, 106, 181, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096987.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 144

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[135, 135, 164, 165]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 165, 165, 165, 165, 165]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 146, 147, 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 134, 164, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[135, 135, 164, 165]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[135, 134, 164, 165]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015014.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 145

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[124, 119, 175, 180]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 173, 173, 173]), array([131, 132, 133, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 119, 174, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[124, 119, 175, 180]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[121, 119, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2482-bbox-1504140857.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 146

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[109,  90, 191, 210]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[109,  90, 191, 210]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999519.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 147

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 129, 171, 171]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 169, 169, 169]), array([135, 136, 137, ..., 155, 156, 157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 131, 168, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[129, 129, 171, 171]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 131, 168, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013909.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 148

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[125, 118, 174, 182]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 183, 183, 183]), array([158, 159, 160, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 122, 174, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[125, 118, 174, 182]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[125, 122, 174, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675464.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 149

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 88,  82, 212, 218]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 68,  68,  68, ..., 228, 228, 228]), array([184, 185, 186, ..., 116, 117, 118]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 79,  68, 236, 228]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 88,  82, 212, 218]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 79,  68, 236, 228]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500499770.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 150

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[101,  76, 199, 223]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 74,  74,  74, ..., 231, 231, 232]), array([ 95,  96,  97, ..., 180, 181, 138]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 82,  74, 204, 232]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[101,  76, 199, 223]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 82,  74, 204, 232]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1887-bbox-1519014865.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 151

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[108, 116, 191, 183]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 191, 191, 191]), array([114, 115, 116, ..., 187, 188, 189]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 110, 205, 191]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[108, 116, 191, 183]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 96, 110, 205, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141463.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 152

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 124, 171, 175]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 173, 173, 173]), array([134, 135, 136, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 129, 172, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[129, 124, 171, 175]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[126, 129, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775492.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 153

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[101,  78, 198, 222]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 88,  88,  88, ..., 211, 211, 211]), array([118, 119, 120, ..., 168, 169, 170]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 91,  88, 193, 211]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[101,  78, 198, 222]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 91,  88, 193, 211]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999544.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 154

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 42,  84, 258, 215]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 67,  67,  67, ..., 225, 225, 225]), array([76, 77, 78, ..., 72, 73, 74]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 40,  67, 255, 225]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 42,  84, 258, 215]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 40,  67, 255, 225]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2452-bbox-1503652385.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 155

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[137, 139, 163, 160]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161]), array([142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[135, 138, 161, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[137, 139, 163, 160]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[135, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534090915.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 156

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[135, 137, 164, 162]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
       166, 166, 166]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 134, 165, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[135, 137, 164, 162]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[133, 134, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879141.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 157

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[102,  98, 198, 201]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 184, 184, 184]), array([142, 143, 144, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 119, 187, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[102,  98, 198, 201]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[118, 119, 187, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748045.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 158

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[117, 119, 182, 181]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 185, 185, 185]), array([157, 158, 159, ..., 140, 141, 142]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 121, 180, 185]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[117, 119, 182, 181]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[122, 121, 180, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539856.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 159

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[113, 101, 186, 198]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 196, 196, 196]), array([119, 120, 121, ..., 134, 135, 136]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112, 104, 183, 196]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[113, 101, 186, 198]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[112, 104, 183, 196]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030577.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 160

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[104,  95, 195, 205]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([100, 100, 100, ..., 195, 195, 195]), array([104, 105, 106, ..., 191, 192, 193]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 91, 100, 203, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[104,  95, 195, 205]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 91, 100, 203, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947644.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 161

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[104, 115, 196, 185]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([111, 111, 111, ..., 189, 189, 189]), array([121, 122, 123, ..., 191, 192, 193]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95, 111, 201, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[104, 115, 196, 185]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 95, 111, 201, 189]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434586.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 162

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[138, 123, 162, 176]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 172, 172, 172]), array([141, 142, 143, ..., 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 131, 166, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[138, 123, 162, 176]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[133, 131, 166, 172]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211899.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 163

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 80,  77, 219, 223]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 91,  91,  91,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,
        92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  93,
        93,  93,  93,  93,  93,  93,  93,  93,  93,  93,  93,  93,  93,
        93,  93,  93,  93,  93,  93,  93,  93,  94,  94,  94,  94,  94,
        94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,
        94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,  94,
        94,  94,  95,  95,  95,  95,  95,  95,  95,  95,  95,  95,  95,
        95,  95,  95,  95,  95,  95,  95,  95,  95,  95,  95,  95,  95,
        95,  95,  95,  95,  95,  95,  95,  95,  96,  96,  96,  96,  96,
        96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,
        96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,  96,
        96,  96,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,
        97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,
        97,  97,  97,  97,  97,  97,  97,  97,  97,  98,  98,  98,  98,
        98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,
        98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,
        98,  98,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
        99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,
        99,  99,  99,  99,  99,  99,  99,  99, 100, 100, 100, 100, 100,
       100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
       100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,
       101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102,
       102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102,
       102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103,
       103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,
       103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104,
       104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104,
       104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 105,
       105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
       105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
       106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,
       106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,
       107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,
       107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108,
       108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,
       108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109,
       109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110,
       110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110,
       110, 110, 110, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111,
       111, 111, 111, 111, 111, 111, 112, 112, 112, 112, 112, 112, 112,
       112, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 113, 113,
       113, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 114, 114,
       114, 114, 114, 114, 114, 115, 115, 115, 115, 115, 115, 115, 115,
       116, 116, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 117,
       117, 118, 118]), array([ 96,  97,  98,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,
       100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,  90,
        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
       104, 105, 106, 107, 108, 109, 110, 111,  88,  89,  90,  91,  92,
        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,
       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,
       119, 120,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
       111, 112, 113, 114, 115, 116, 117, 118,  86,  87,  88,  89,  90,
        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,
       117, 118,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
       110, 111, 112, 113, 114, 115, 116, 117, 118,  86,  87,  88,  89,
        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,
       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,
       116, 117,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,
        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,
       108, 109, 110, 111, 112, 113, 114, 115,  84,  85,  86,  87,  88,
        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,
        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
       110, 111, 112, 113, 114,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113,  84,  85,  86,  87,
        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,
       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,  84,  85,
        86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,
        99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,  84,
        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,
        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,
        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,
        97,  98,  99, 100, 101, 102, 103, 104, 105, 106,  86,  87,  88,
        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,
       102, 103, 104, 105,  86,  87,  88,  89,  90,  91,  92,  93,  94,
        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,  86,  87,
        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,
       101, 102, 103,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,
        96,  97,  98,  99, 100, 101,  87,  88,  89,  90,  91,  92,  93,
        94,  95,  96,  97,  98,  99,  87,  88,  89,  90,  91,  92,  93,
        94,  95,  96,  97,  98,  99,  87,  88,  89,  90,  91,  92,  93,
        94,  95,  96,  97,  98,  88,  89,  90,  91,  92,  93,  94,  95,
        88,  89,  90,  91,  92,  93,  94,  88,  89,  90,  91,  92,  93,
        94,  90,  91]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 87,  87,  87, ..., 212, 212, 212]), array([143, 144, 145, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 84,  91, 120, 118],
        [ 90,  87, 204, 212]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([3, 5])
new_targets: [{'boxes': tensor([[ 80,  77, 219, 223]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 84,  91, 120, 118],
        [ 90,  87, 204, 212]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030606.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 164

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[102,  87, 197, 212]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 197, 197, 197]), array([126, 127, 128, ..., 139, 140, 141]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[111, 104, 181, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[102,  87, 197, 212]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[111, 104, 181, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095137-bbox-1500962989.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 165

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[110, 106, 189, 194]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([114, 114, 114, ..., 193, 193, 193]), array([122, 123, 124, ..., 128, 129, 130]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[110, 114, 188, 193]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[110, 106, 189, 194]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[110, 114, 188, 193]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748040.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 166

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[108,  94, 191, 206]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 197, 197, 197]), array([166, 167, 168, ..., 139, 140, 141]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118,  96, 181, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[108,  94, 191, 206]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[118,  96, 181, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539646.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 167

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[125, 128, 174, 172]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, ..., 169, 169, 169]), array([150, 151, 152, ..., 150, 151, 152]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 133, 166, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[125, 128, 174, 172]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[129, 133, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102979.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 168

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[123, 124, 176, 175]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 173, 173, 173]), array([143, 144, 145, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 126, 174, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[123, 124, 176, 175]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[126, 126, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227961.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 169

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[108,  99, 191, 200]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 184, 184, 184]), array([125, 126, 127, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[116, 115, 184, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[108,  99, 191, 200]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[116, 115, 184, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1876-bbox-1518941256.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 170

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[128, 128, 171, 172]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 170, 170, 170]), array([133, 134, 135, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 129, 170, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[128, 128, 171, 172]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[127, 129, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604272.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 171

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 90,  75, 210, 224]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 95,  95,  95, ..., 204, 204, 204]), array([170, 171, 172, ..., 120, 121, 122]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 91,  95, 199, 204]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 90,  75, 210, 224]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 91,  95, 199, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_3901-bbox-1533822128.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 172

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[114, 123, 186, 176]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 176, 176, 176]), array([157, 158, 159, ..., 172, 173, 174]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 123, 180, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[114, 123, 186, 176]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[118, 123, 180, 176]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161634-bbox-1415718444.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 173

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[131, 124, 169, 175]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 168, 168, 168]), array([141, 142, 143, ..., 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 129, 164, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[131, 124, 169, 175]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[133, 129, 164, 168]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2598-bbox-1499561022.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 174

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 71,  94, 229, 205]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 95,  95,  95, ..., 203, 203, 203]), array([137, 138, 139, ..., 197, 198, 199]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 80,  95, 217, 203]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 71,  94, 229, 205]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 80,  95, 217, 203]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595384.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 175

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[139, 138, 161, 162]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163,
       163, 164, 164, 164, 164, 164, 164, 164]), array([149, 150, 151, 152, 153, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 147, 148, 149, 150, 151, 152,
       153, 147, 148, 149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 138, 162, 164]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[139, 138, 161, 162]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 138, 162, 164]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014505.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 176

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[126, 126, 173, 174]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 172, 172, 172]), array([150, 151, 152, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 127, 172, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[126, 126, 173, 174]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[125, 127, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533753.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 177

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[117, 107, 183, 193]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 180, 180, 180]), array([142, 143, 144, ..., 147, 148, 149]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 122, 168, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[117, 107, 183, 193]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[129, 122, 168, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539647.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 178

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 95, 102, 205, 198]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 204, 204, 204]), array([133, 134, 135, ..., 186, 187, 188]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 92,  96, 203, 204]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 95, 102, 205, 198]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 92,  96, 203, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434612.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 179

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[127, 103, 172, 196]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 184, 184, 184]), array([142, 143, 144, ..., 159, 160, 161]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 115, 170, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[127, 103, 172, 196]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 115, 170, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671387.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 180

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 63,  45, 237, 254]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 84,  84,  84, ..., 224, 224, 224]), array([154, 155, 156, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 78,  84, 237, 224]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 63,  45, 237, 254]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 78,  84, 237, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105414.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 181

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[ 88,  94, 211, 206]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([ 90,  90,  90, ..., 212, 212, 212]), array([179, 180, 181, ..., 189, 190, 191]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 88,  90, 209, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[ 88,  94, 211, 206]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[ 88,  90, 209, 212]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604252.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 182

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 127, 173, 173]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 170, 170, 170]), array([138, 139, 140, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 129, 172, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[127, 127, 173, 173]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[129, 129, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161634-bbox-1415718433.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 183

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[121, 123, 179, 177]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 178, 178, 178]), array([133, 134, 135, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 122, 185, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[121, 123, 179, 177]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 122, 185, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524305.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 184

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[114, 112, 185, 187]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 183, 183, 183]), array([158, 159, 160, ..., 168, 169, 170]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 115, 184, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[114, 112, 185, 187]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[115, 115, 184, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1519910868.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 185

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[118,  95, 182, 204]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 207, 207, 207]), array([165, 166, 167, ..., 146, 147, 148]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95,  96, 196, 207]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[118,  95, 182, 204]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 95,  96, 196, 207]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673162.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 186

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[136, 136, 164, 164]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([118, 118, 118, ..., 169, 169, 169]), array([159, 160, 161, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 118, 176, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[136, 136, 164, 164]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 118, 176, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2766-bbox-1530054833.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 187

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[135, 129, 165, 171]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 170, 170, 170]), array([141, 142, 143, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 131, 168, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[135, 129, 165, 171]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[133, 131, 168, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533759.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 188

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 87,  66, 212, 233]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 64,  64,  64, ..., 247, 247, 247]), array([193, 194, 195, ..., 185, 186, 187]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 74,  64, 227, 247]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 87,  66, 212, 233]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 74,  64, 227, 247]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595385.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 189

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[124, 121, 176, 179]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 170, 170, 170]), array([146, 147, 148, ..., 159, 160, 161]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 126, 170, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[124, 121, 176, 179]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[129, 126, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4532-bbox-1533854039.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 190

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 102, 171, 198]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([103, 103, 103, ..., 197, 197, 197]), array([173, 174, 175, ..., 194, 195, 196]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, ..., 189, 189, 189]), array([138, 139, 140, ..., 140, 141, 142]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 103, 217, 197],
        [127, 133, 157, 189]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([1, 3])
new_targets: [{'boxes': tensor([[129, 102, 171, 198]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 103, 217, 197],
        [127, 133, 157, 189]]), 'scores': tensor([1, 1]), 'labels': tensor([1, 3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604281.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 191

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[119, 121, 181, 179]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 180, 180, 180]), array([127, 128, 129, ..., 130, 131, 132]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 121, 178, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[119, 121, 181, 179]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[118, 121, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_094448-bbox-1418427497.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 192

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[118, 115, 181, 184]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 181, 181, 181]), array([129, 130, 131, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 116, 183, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[118, 115, 181, 184]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[118, 116, 183, 181]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227933.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 193

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[131, 125, 169, 174]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, 131, 131, 131, 132, 132, 132, 132, 132, 132, 133,
       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,
       134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 134, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163,
       163, 163, 163, 164, 164, 164, 164, 164]), array([149, 150, 151, 152, 153, 154, 149, 150, 151, 152, 153, 154, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 146, 147,
       148, 149, 150, 146, 147, 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 131, 164, 164]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[131, 125, 169, 174]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[138, 131, 164, 164]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2562-bbox-1506386819.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 194

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 95, 101, 204, 199]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 207, 207, 207]), array([166, 167, 168, ..., 124, 125, 126]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 94,  96, 211, 207]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 95, 101, 204, 199]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 94,  96, 211, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141461.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 195

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[121, 123, 179, 176]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 170, 170, 170]), array([129, 130, 131, ..., 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 129, 166, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[121, 123, 179, 176]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[122, 129, 166, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675948.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 196

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 93,  98, 207, 202]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 201, 201, 201]), array([110, 111, 112, ..., 185, 186, 187]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[103,  96, 200, 201]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 93,  98, 207, 202]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[103,  96, 200, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530737130.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 197

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[106,  82, 194, 217]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 79,  79,  79, ..., 221, 221, 221]), array([186, 187, 188, ..., 185, 186, 187]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 78,  79, 221, 221]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[106,  82, 194, 217]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 78,  79, 221, 221]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_3901-bbox-1533822142.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 198

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 66,  77, 234, 223]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 82,  82,  82, ..., 224, 224, 224]), array([167, 168, 169, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 72,  82, 220, 224]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 66,  77, 234, 223]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 72,  82, 220, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947869.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 199

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[120, 105, 180, 194]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 180, 180, 180]), array([135, 136, 137, ..., 140, 141, 142]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 123, 168, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[120, 105, 180, 194]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[126, 123, 168, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540435.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 200

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[138, 139, 162, 161]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161]), array([143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 141, 161, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[138, 139, 162, 161]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[138, 141, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013877.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 201

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[139, 139, 161, 161]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161]), array([142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 147, 148]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 141, 160, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[139, 139, 161, 161]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[138, 141, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534090997.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 202

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[133, 129, 167, 171]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, ..., 168, 168, 168]), array([139, 140, 141, ..., 146, 147, 148]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 133, 166, 168]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[133, 129, 167, 171]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 133, 166, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092252-bbox-1418298951.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 203

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[123,  81, 177, 219]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([100, 100, 100, ..., 196, 196, 196]), array([129, 130, 131, ..., 135, 136, 137]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 100, 181, 196]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[123,  81, 177, 219]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[118, 100, 181, 196]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332531.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 204

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[107, 113, 192, 186]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 183, 183, 183]), array([127, 128, 129, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 116, 180, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[107, 113, 192, 186]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[115, 116, 180, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120314-bbox-1533675703.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 205

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[138, 138, 161, 161]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161,
       161, 161, 161]), array([149, 150, 151, 152, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 145, 146, 147, 148, 149, 150,
       151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 138, 161, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[138, 138, 161, 161]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[138, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014507.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 206

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 89, 100, 211, 200]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 84,  84,  84, ..., 221, 221, 221]), array([192, 193, 194, ..., 185, 186, 187]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 90,  84, 211, 221]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 89, 100, 211, 200]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 90,  84, 211, 221]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3924-bbox-1531263977.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 207

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[102,  99, 197, 200]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 189, 189, 189]), array([119, 120, 121, ..., 185, 186, 187]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[103, 104, 199, 189]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[102,  99, 197, 200]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[103, 104, 199, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105416.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 208

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[144, 142, 155, 157]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127,
       127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
       127, 127, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
       128, 128, 128, 128, 128, 129, 129, 129, 129, 129, 129, 129, 129,
       129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,
       130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130,
       130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 131, 131,
       131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131,
       131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 132,
       132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
       132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,
       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,
       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,
       133, 133, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 134, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160]), array([135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 131, 132,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 131,
       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 130, 131, 132, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 130, 131, 132,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 130, 131, 132, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 130, 131, 132, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 130, 131, 132, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 130, 131, 132, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 130, 131, 132, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 131, 132, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 131, 132, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 126, 162, 160]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[144, 142, 155, 157]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[130, 126, 162, 160]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796973.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 209

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[129, 128, 170, 171]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 172, 172, 172]), array([143, 144, 145, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 130, 172, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[129, 128, 170, 171]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 130, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161557-bbox-1415718285.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 210

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[131, 132, 169, 168]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 166, 166, 166, 166, 166, 166, 166, 166]), array([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 146, 147, 148, 149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 134, 165, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[131, 132, 169, 168]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[134, 134, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161627-bbox-1415718401.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 211

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[135, 121, 164, 179]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 127, ..., 172, 172, 172]), array([149, 150, 143, ..., 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 126, 166, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[135, 121, 164, 179]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[133, 126, 166, 172]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1884-bbox-1519001513.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 212

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[128,  97, 171, 202]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 170, 170, 170]), array([139, 140, 141, ..., 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 120, 120, 121, 121, 121, 122, 122, 123, 123, 123, 124,
       124, 124, 125, 125, 126, 126, 126, 127, 127, 127, 128, 128, 128,
       129, 129, 129, 130, 130, 130, 131, 131, 131, 132, 132, 132, 133,
       133, 133, 134, 134, 134, 135, 135, 135, 135, 135, 136, 136, 136,
       136, 136, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,
       139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 141,
       141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142,
       142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144,
       144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145,
       146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157,
       157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159,
       159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160,
       161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162, 162,
       162, 163, 163, 163, 163, 163, 164, 164, 164, 164, 164, 165, 165,
       165, 165, 166, 166, 166, 166, 167, 167, 168, 168, 169, 169, 170,
       170]), array([137, 138, 137, 138, 134, 135, 136, 133, 134, 131, 132, 133, 131,
       132, 133, 131, 132, 130, 131, 132, 130, 131, 132, 130, 131, 132,
       130, 131, 132, 130, 131, 132, 130, 131, 132, 130, 131, 132, 130,
       131, 132, 130, 131, 132, 129, 130, 131, 132, 133, 129, 130, 131,
       132, 133, 129, 130, 131, 132, 133, 129, 130, 131, 132, 133, 134,
       129, 130, 131, 132, 133, 134, 129, 130, 131, 132, 133, 134, 129,
       130, 131, 132, 133, 134, 135, 136, 129, 130, 131, 132, 133, 134,
       135, 136, 129, 130, 131, 132, 133, 134, 135, 136, 129, 130, 131,
       132, 133, 134, 135, 136, 129, 130, 131, 132, 133, 134, 135, 136,
       129, 130, 131, 132, 133, 134, 135, 136, 129, 130, 131, 132, 133,
       134, 135, 136, 137, 129, 130, 131, 132, 133, 134, 135, 136, 137,
       129, 130, 131, 132, 133, 134, 135, 136, 137, 129, 130, 131, 132,
       133, 134, 135, 136, 137, 129, 130, 131, 132, 133, 134, 135, 136,
       137, 129, 130, 131, 132, 133, 134, 135, 136, 137, 129, 130, 131,
       132, 133, 134, 135, 136, 137, 129, 130, 131, 132, 133, 134, 135,
       136, 137, 129, 130, 131, 132, 133, 134, 135, 136, 137, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 130, 131, 132, 133, 134, 135,
       136, 137, 130, 131, 132, 133, 134, 135, 136, 137, 130, 131, 132,
       133, 134, 135, 136, 137, 130, 131, 132, 133, 134, 135, 136, 137,
       130, 131, 132, 133, 134, 135, 136, 130, 131, 132, 133, 134, 135,
       136, 130, 131, 132, 133, 134, 130, 131, 132, 133, 134, 131, 132,
       133, 134, 131, 132, 133, 134, 133, 134, 133, 134, 133, 134, 135,
       136]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 119, 168, 170],
        [129, 119, 138, 170]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([3, 5])
new_targets: [{'boxes': tensor([[128,  97, 171, 202]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[133, 119, 168, 170],
        [129, 119, 138, 170]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585512.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 213

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[136, 129, 164, 170]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 176, 176, 176]), array([145, 146, 147, ..., 136, 137, 138]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 129, 173, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[136, 129, 164, 170]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[122, 129, 173, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533748.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 214

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[130, 128, 169, 172]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 170, 170, 170]), array([139, 140, 141, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 131, 170, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[130, 128, 169, 172]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[129, 131, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785688.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 215

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 94, 112, 205, 188]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 178, 178, 178]), array([116, 117, 118, ..., 116, 117, 118]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[103, 119, 191, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 94, 112, 205, 188]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[103, 119, 191, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671366.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 216

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[125, 120, 175, 179]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 178, 178, 178]), array([165, 166, 167, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 123, 176, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[125, 120, 175, 179]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[125, 123, 176, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013911.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 217

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 79, 101, 221, 199]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 82,  82,  82, ..., 220, 220, 220]), array([189, 190, 191, ..., 201, 202, 203]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 72,  82, 224, 220]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 79, 101, 221, 199]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 72,  82, 224, 220]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930928.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 218

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 125, 173, 174]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 172, 172, 172]), array([157, 158, 159, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 127, 172, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[127, 125, 173, 174]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[127, 127, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014508.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 219

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[112, 104, 188, 196]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([103, 103, 103, ..., 197, 197, 197]), array([181, 182, 183, ..., 124, 125, 126]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[106, 103, 196, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[112, 104, 188, 196]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[106, 103, 196, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527552588.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 220

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[124, 120, 175, 179]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 176, 176, 176]), array([129, 130, 131, ..., 140, 141, 142]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 125, 170, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[124, 120, 175, 179]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 125, 170, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527535106.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 221

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[100, 124, 199, 175]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 178, 178, 178]), array([123, 124, 125, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112, 123, 181, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[100, 124, 199, 175]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[112, 123, 181, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673161.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 222

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 134, 164, 166]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164]), array([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 134, 164, 164]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 134, 164, 166]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[134, 134, 164, 164]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_110955-bbox-1416788116.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 223

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[115, 122, 184, 178]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 196, 196, 197]), array([119, 120, 121, ..., 191, 192, 126]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[110, 107, 201, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[115, 122, 184, 178]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[110, 107, 201, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_091623-bbox-1500499877.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 224

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[132, 128, 168, 172]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([129, 129, 129, ..., 170, 170, 170]), array([146, 147, 148, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 129, 169, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[132, 128, 168, 172]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[130, 129, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015016.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 225

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 86,  93, 213, 206]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 90,  90,  90, ..., 208, 208, 208]), array([155, 156, 157, ..., 189, 190, 191]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 92,  90, 208, 208]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 86,  93, 213, 206]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 92,  90, 208, 208]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3633-bbox-1506586888.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 226

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[138, 140, 161, 160]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 166, 166,
       166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166]), array([141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 135, 165, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[138, 140, 161, 160]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[134, 135, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796981.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 227

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[125, 127, 175, 173]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 188, 188, 188]), array([116, 117, 118, ..., 118, 119, 120]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[100, 110, 200, 188]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[125, 127, 175, 173]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[100, 110, 200, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001601.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 228

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 52,  46, 247, 254]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 51,  51,  51, ..., 240, 240, 240]), array([155, 156, 157, ..., 191, 192, 193]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 57,  51, 232, 240]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 52,  46, 247, 254]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 57,  51, 232, 240]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595382.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 229

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[120, 120, 179, 179]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 178, 178, 178]), array([129, 130, 131, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 123, 177, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[120, 120, 179, 179]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[118, 123, 177, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776111.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 230

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 125, 172, 175]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([127, 127, 127, ..., 173, 173, 173]), array([131, 132, 133, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 127, 172, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[127, 125, 172, 175]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[126, 127, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_142609-bbox-1418602379.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 231

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[112, 101, 188, 198]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 195, 195, 195]), array([166, 167, 168, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 107, 188, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[112, 101, 188, 198]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[115, 107, 188, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104711.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 232

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[132, 131, 168, 168]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, ..., 166, 166, 166]), array([141, 142, 143, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 134, 166, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[132, 131, 168, 168]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 134, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776082.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 233

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[131, 130, 168, 170]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 169, 169, 169]), array([141, 142, 143, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 131, 168, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[131, 130, 168, 170]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 131, 168, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092113-bbox-1418087508.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 234

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[130, 128, 170, 171]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 173, 173, 173]), array([141, 142, 143, ..., 152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 125, 170, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[130, 128, 170, 171]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 125, 170, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478041.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 235

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[116, 106, 183, 194]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 94,  94,  94, ..., 199, 199, 199]), array([146, 147, 148, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[111,  94, 180, 199]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[116, 106, 183, 194]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[111,  94, 180, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530732963.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 236

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 98, 126, 202, 173]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([114, 114, 114, ..., 188, 188, 188]), array([106, 107, 108, ..., 120, 121, 122]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96, 114, 209, 188]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 98, 126, 202, 173]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 96, 114, 209, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434743.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 237

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[128, 120, 172, 180]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([111, 112, 112, ..., 184, 184, 184]), array([162, 154, 155, ..., 143, 144, 145]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[111, 111, 183, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[128, 120, 172, 180]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[111, 111, 183, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227905.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 238

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 82,  63, 218, 236]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 64,  64,  64, ..., 224, 224, 224]), array([159, 160, 161, ..., 120, 121, 122]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 84,  64, 211, 224]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 82,  63, 218, 236]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 84,  64, 211, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1876-bbox-1518941263.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 239

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[136, 130, 163, 170]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162, 162,
       162]), array([147, 148, 149, 150, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 147, 148, 149, 150, 151, 152,
       153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 137, 161, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 130, 163, 170]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[138, 137, 161, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2797-bbox-1531447964.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 240

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 89,  94, 211, 206]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 88,  88,  88, ..., 207, 207, 207]), array([185, 186, 187, ..., 194, 195, 196]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 75,  88, 216, 207]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 89,  94, 211, 206]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 75,  88, 216, 207]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865796.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 241

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 83, 119, 216, 181]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 161, 161, 161]), array([153, 154, 155, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 126, 192, 161]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 83, 119, 216, 181]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[130, 126, 192, 161]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540462.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 242

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[119, 118, 180, 181]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 183, 183, 183]), array([163, 164, 165, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 115, 180, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[119, 118, 180, 181]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[119, 115, 180, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013964.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 243

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[108, 120, 191, 180]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([104, 104, 104, ..., 195, 195, 195]), array([177, 178, 179, ..., 118, 119, 120]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[103, 104, 199, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[108, 120, 191, 180]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[103, 104, 199, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434937.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 244

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 86,  94, 214, 206]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 174, 174, 174]), array([130, 131, 132, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 123, 174, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 86,  94, 214, 206]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 123, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673175.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 245

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[122, 122, 177, 177]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 172, 172, 172]), array([146, 147, 148, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 126, 170, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[122, 122, 177, 177]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[125, 126, 170, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675457.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 246

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[127, 122, 173, 177]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 170, 170, 170]), array([143, 144, 145, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 126, 174, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[127, 122, 173, 177]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[126, 126, 174, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4533-bbox-1533854132.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 247

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[118, 117, 181, 182]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 177, 177, 177]), array([139, 140, 141, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 123, 176, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[118, 117, 181, 182]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[123, 123, 176, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096981.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 248

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 66,  81, 234, 218]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 80,  80,  80, ..., 232, 232, 232]), array([186, 187, 188, ..., 101, 102, 103]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 64,  80, 235, 232]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 66,  81, 234, 218]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 64,  80, 235, 232]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671365.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 249

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[123, 112, 177, 188]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 184, 184, 184]), array([151, 152, 153, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 119, 174, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[123, 112, 177, 188]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[123, 119, 174, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104764.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 250

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[122, 114, 177, 186]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 188, 188, 188]), array([154, 155, 156, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 115, 178, 188]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[122, 114, 177, 186]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[115, 115, 178, 188]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1501095756.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 251

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 137, 164, 162]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136,
       136, 136, 136, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 162, 162,
       162, 162, 162, 162, 162]), array([147, 148, 149, 150, 151, 152, 153, 154, 147, 148, 149, 150, 151,
       152, 153, 154, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 147, 148,
       149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 135, 162, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 137, 164, 162]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 135, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012710.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 252

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[198, 142, 216, 158]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[198, 142, 216, 158]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445786.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 253

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[139, 136, 161, 163]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 132,
       132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 133, 133,
       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,
       133, 133, 133, 133, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 166, 166, 166, 166, 166, 166,
       166, 166, 166]), array([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 166, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 166, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 166, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 166, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 166, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 166, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 166, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       166, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 166, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 166, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 166, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       166, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 146, 147, 148, 149, 150, 151,
       152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[134, 131, 166, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[139, 136, 161, 163]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[134, 131, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796998.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 254

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[128, 126, 172, 173]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 172, 172, 172]), array([162, 163, 164, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 126, 174, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[128, 126, 172, 173]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[126, 126, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014515.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 255

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[122, 126, 178, 173]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 172, 172, 172]), array([129, 130, 131, ..., 144, 145, 146]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 126, 174, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[122, 126, 178, 173]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[123, 126, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348206.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 256

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 138, 163, 161]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       157, 157, 157, 157, 157, 157, 157]), array([147, 148, 149, 150, 151, 152, 153, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       147, 148, 149, 150, 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[145, 145, 156, 157]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 138, 163, 161]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[145, 145, 156, 157]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102981.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 257

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 78,  92, 222, 207]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 64,  64,  64, ..., 237, 237, 237]), array([ 88,  89,  90, ..., 172, 173, 174]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 70,  64, 233, 237]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 78,  92, 222, 207]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 70,  64, 233, 237]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999517.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 258

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 88, 108, 212, 191]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 192, 192, 192]), array([171, 172, 173, ..., 183, 184, 185]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 91, 106, 201, 192]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 88, 108, 212, 191]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 91, 106, 201, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105412.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 259

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[130, 101, 170, 199]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 88,  88,  88, ..., 201, 201, 201]), array([125, 126, 127, ..., 143, 144, 145]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[116,  88, 185, 201]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[130, 101, 170, 199]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[116,  88, 185, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1887-bbox-1519014887.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 260

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[103, 139, 131, 160]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[103, 139, 131, 160]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445788.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 261

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[135, 115, 165, 185]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 176, 176, 176]), array([134, 135, 136, ..., 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[126, 116, 180, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[135, 115, 165, 185]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[126, 116, 180, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524840.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 262

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 94, 102, 206, 198]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 193, 193, 193]), array([169, 170, 171, ..., 182, 183, 184]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([106, 106, 106, ..., 150, 150, 150]), array([115, 116, 117, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[102, 106, 193, 193],
        [102, 106, 170, 150]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([3, 5])
new_targets: [{'boxes': tensor([[ 94, 102, 206, 198]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[102, 106, 193, 193],
        [102, 106, 170, 150]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748101.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 263

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[101, 119, 199, 180]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 191, 191, 191]), array([115, 116, 117, ..., 118, 119, 120]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[102, 115, 203, 191]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[101, 119, 199, 180]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[102, 115, 203, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610358.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 264

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[149, 117, 210, 183]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 183, 183, 183]), array([173, 174, 175, ..., 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 122, 187, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[149, 117, 210, 183]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[131, 122, 187, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014513.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 265

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[118,  86, 182, 213]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 88,  88,  88, ..., 212, 212, 212]), array([122, 123, 124, ..., 139, 140, 141]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[110,  88, 192, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[118,  86, 182, 213]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[110,  88, 192, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078060.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 266

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[136, 137, 164, 163]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 162, 162, 162, 162]), array([149, 150, 151, 152, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 147, 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[138, 138, 161, 162]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[136, 137, 164, 163]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[138, 138, 161, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012708.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 267

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[139, 138, 161, 162]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158,
       158, 158]), array([145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 146, 147, 148,
       149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[139, 141, 158, 158]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[139, 138, 161, 162]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[139, 141, 158, 158]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_111804-bbox-1416831263.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 268

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[118, 119, 181, 180]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([125, 125, 125, ..., 172, 172, 172]), array([130, 131, 132, ..., 159, 160, 161]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 125, 174, 172]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[118, 119, 181, 180]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[123, 125, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675952.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 269

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[110, 111, 190, 188]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([103, 103, 103, ..., 192, 192, 192]), array([162, 163, 164, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[110, 103, 188, 192]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[110, 111, 190, 188]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[110, 103, 188, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610347.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 270

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[110,  85, 189, 215]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 88,  88,  88, ..., 216, 216, 216]), array([116, 117, 118, ..., 128, 129, 130]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[102,  88, 192, 216]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[110,  85, 189, 215]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[102,  88, 192, 216]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332497.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 271

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[119, 118, 180, 181]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 164, 164, 164]), array([146, 147, 148, ..., 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 132, 132, 133, 133, 134, 134, 134, 134, 135, 135, 135,
       135, 135, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137,
       137, 138, 138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139,
       139, 139, 139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 141,
       141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142,
       142, 142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146, 146,
       146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149,
       149, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151,
       151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 153, 153, 153,
       153, 153, 154, 154, 154, 155, 155, 156, 156]), array([127, 128, 127, 128, 127, 128, 126, 127, 128, 129, 126, 127, 128,
       129, 130, 126, 127, 128, 129, 130, 126, 127, 128, 129, 130, 131,
       132, 126, 127, 128, 129, 130, 131, 132, 133, 126, 127, 128, 129,
       130, 131, 132, 133, 126, 127, 128, 129, 130, 131, 132, 133, 127,
       128, 129, 130, 131, 132, 133, 134, 127, 128, 129, 130, 131, 132,
       133, 134, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 127,
       128, 129, 130, 131, 132, 133, 134, 135, 136, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 129, 130, 131, 132, 133, 134, 135,
       136, 129, 130, 131, 132, 133, 134, 135, 136, 137, 129, 130, 131,
       132, 133, 134, 135, 136, 137, 130, 131, 132, 133, 134, 135, 136,
       137, 130, 131, 132, 133, 134, 135, 136, 137, 131, 132, 133, 134,
       135, 136, 137, 131, 132, 133, 134, 135, 136, 137, 133, 134, 135,
       136, 137, 134, 135, 136, 135, 136, 135, 136]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 119, 172, 164],
        [126, 131, 137, 156]])
predicted_scores: tensor([1, 1])
predicted_labels: tensor([3, 5])
new_targets: [{'boxes': tensor([[119, 118, 180, 181]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 119, 172, 164],
        [126, 131, 137, 156]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527532582.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 272

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 84,  88, 216, 212]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([116, 116, 116, ..., 181, 181, 181]), array([166, 167, 168, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[110, 116, 193, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 84,  88, 216, 212]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[110, 116, 193, 181]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679973.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 273

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[113, 119, 187, 180]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 173, 173, 173]), array([131, 132, 133, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 119, 172, 173]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[113, 119, 187, 180]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 119, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673155.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 274

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[131, 134, 169, 166]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 169, 169, 169]), array([141, 142, 143, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[129, 130, 170, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[131, 134, 169, 166]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[129, 130, 170, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879130.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 275

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[109, 109, 190, 190]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([110, 110, 110, ..., 184, 184, 184]), array([119, 120, 121, ..., 178, 179, 180]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[103, 110, 192, 184]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[109, 109, 190, 190]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[103, 110, 192, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104759.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 276

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 122, 173, 177]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 174, 174, 174]), array([133, 134, 135, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 126, 173, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[127, 122, 173, 177]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[127, 126, 173, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348202.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 277

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 80,  79, 219, 221]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 91,  91,  91, ..., 212, 212, 212]), array([126, 127, 128, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 91,  91, 205, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 80,  79, 219, 221]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 91,  91, 205, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947781.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 278

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 95, 110, 205, 190]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 87,  87,  87, ..., 212, 212, 212]), array([161, 162, 163, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 94,  87, 211, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 95, 110, 205, 190]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 94,  87, 211, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2423-bbox-1501245589.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 279

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[127, 128, 173, 171]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 169, 169, 169]), array([139, 140, 141, ..., 151, 152, 153]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 131, 169, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[127, 128, 173, 171]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[130, 131, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013876.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 280

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 81, 103, 219, 196]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 63,  63,  63, ..., 244, 244, 244]), array([137, 138, 139, ..., 164, 165, 166]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 74,  63, 236, 244]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 81, 103, 219, 196]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 74,  63, 236, 244]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947965.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 281

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[113, 112, 187, 187]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([112, 112, 112, ..., 180, 180, 180]), array([130, 131, 132, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[116, 112, 178, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[113, 112, 187, 187]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[116, 112, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_164849-bbox-1530660763.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 282

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[117, 121, 183, 178]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 178, 178, 178]), array([133, 134, 135, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 123, 180, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[117, 121, 183, 178]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 123, 180, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434529.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 283

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 97, 103, 203, 196]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 96,  96,  96, ..., 197, 197, 197]), array([119, 120, 121, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 99,  96, 193, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 97, 103, 203, 196]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 99,  96, 193, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332542.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 284

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[127, 121, 172, 179]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 176, 176, 176]), array([130, 131, 132, ..., 156, 157, 158]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 122, 172, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[127, 121, 172, 179]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[121, 122, 172, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001609.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 285

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[119, 122, 181, 178]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 181, 181, 181]), array([157, 158, 159, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 121, 180, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[119, 122, 181, 178]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 121, 180, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141515.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 286

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[131, 130, 168, 170]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,
       134, 134, 134, 134, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165, 165, 165]), array([141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 133, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 131, 132,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 131, 132, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 131, 132, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 131, 132, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 131,
       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 131, 132, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 131, 132, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 131, 132, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 131, 132, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 131, 132,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 131, 132, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 134, 164, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[131, 130, 168, 170]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[131, 134, 164, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102982.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 287

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[138, 133, 162, 166]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([139, 139, 139, 139, 139, 139, 139, 139, 140, 140, 140, 140, 140,
       140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158]), array([146, 147, 148, 149, 150, 151, 152, 153, 146, 147, 148, 149, 150,
       151, 152, 153, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[141, 139, 160, 158]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[138, 133, 162, 166]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[141, 139, 160, 158]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015018.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 288

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[123, 105, 177, 194]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 95,  95,  95, ..., 199, 199, 199]), array([133, 134, 135, ..., 135, 136, 137]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[116,  95, 185, 199]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[123, 105, 177, 194]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[116,  95, 185, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211972.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 289

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[127, 119, 172, 181]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([119, 119, 119, ..., 177, 177, 177]), array([150, 151, 152, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 119, 173, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[127, 119, 172, 181]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[123, 119, 173, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675954.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 290

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[128, 123, 172, 177]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 177, 177, 177]), array([133, 134, 135, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[123, 121, 178, 177]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[128, 123, 172, 177]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[123, 121, 178, 177]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818817.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 291

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[118, 119, 181, 180]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([115, 115, 115, ..., 183, 183, 183]), array([161, 162, 163, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[115, 115, 183, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[118, 119, 181, 180]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[115, 115, 183, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012700.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 292

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 99,  86, 201, 213]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 92,  92,  92, ..., 204, 204, 204]), array([116, 117, 118, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 92,  92, 211, 204]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 99,  86, 201, 213]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 92,  92, 211, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865815.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 293

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[138, 138, 162, 161]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160]), array([147, 148, 149, 150, 151, 152, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[137, 137, 161, 160]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[138, 138, 162, 161]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[137, 137, 161, 160]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012712.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 294

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[114,  93, 186, 207]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 82,  82,  82, ..., 216, 216, 216]), array([146, 147, 148, ..., 190, 191, 192]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 78,  82, 224, 216]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[114,  93, 186, 207]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 78,  82, 224, 216]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212067.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 295

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[114, 119, 185, 180]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 178, 178, 178]), array([127, 128, 129, ..., 163, 164, 165]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[122, 130, 176, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[114, 119, 185, 180]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[122, 130, 176, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865789.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 296

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[126, 124, 173, 176]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 174, 174, 174]), array([139, 140, 141, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 123, 173, 174]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[126, 124, 173, 176]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 123, 173, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524312.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 297

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[123, 126, 177, 173]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([133, 133, 133, ..., 170, 170, 170]), array([145, 146, 147, ..., 160, 161, 162]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 133, 169, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[123, 126, 177, 173]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 133, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102976.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 298

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[124, 129, 175, 171]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 180, 180, 180]), array([135, 136, 137, ..., 168, 169, 170]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 131, 178, 180]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[124, 129, 175, 171]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 131, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_091623-bbox-1500499878.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 299

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[134, 138, 165, 162]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[134, 138, 165, 162]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797235.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 300

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[ 89,  88, 211, 212]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 87,  87,  87, ..., 212, 212, 212]), array([100, 101, 102, ..., 186, 187, 188]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 92,  87, 208, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[ 89,  88, 211, 212]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[ 92,  87, 208, 212]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652324.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 301

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[ 71,  82, 228, 218]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([ 91,  91,  91, ..., 211, 211, 211]), array([190, 191, 192, ..., 107, 108, 109]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 87,  91, 220, 211]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[ 71,  82, 228, 218]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[ 87,  91, 220, 211]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-06-02-vianopolis-go-20230602_135136-bbox-1407347295.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 302

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[120, 121, 179, 178]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 178, 178, 178]), array([162, 163, 164, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 121, 180, 178]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[120, 121, 179, 178]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[121, 121, 180, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013916.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 303

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[122, 125, 178, 174]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([118, 118, 118, ..., 176, 176, 176]), array([134, 135, 136, ..., 176, 177, 178]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[107, 118, 195, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[122, 125, 178, 174]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[107, 118, 195, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030594.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 304

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[100,  92, 200, 207]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 98,  98,  98, ..., 197, 197, 197]), array([179, 180, 181, ..., 175, 176, 177]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[102,  98, 195, 197]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[100,  92, 200, 207]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[102,  98, 195, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679955.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 305

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[118, 122, 182, 178]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([123, 123, 123, ..., 169, 169, 169]), array([154, 155, 156, ..., 167, 168, 169]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[121, 123, 177, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[118, 122, 182, 178]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[121, 123, 177, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533736.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 306

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[127, 128, 173, 171]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([130, 130, 130, ..., 169, 169, 169]), array([142, 143, 144, ..., 158, 159, 160]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[130, 130, 169, 169]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[127, 128, 173, 171]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[130, 130, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104722.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 307

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[127, 126, 172, 174]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([])
predicted_scores: tensor([])
predicted_labels: tensor([])
new_targets: [{'boxes': tensor([[127, 126, 172, 174]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478002.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 308

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[128, 125, 172, 174]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([126, 126, 126, ..., 170, 170, 170]), array([137, 138, 139, ..., 162, 163, 164]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[125, 126, 172, 170]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[128, 125, 172, 174]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[125, 126, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434960.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 309

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[117, 129, 182, 171]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 176, 176, 176]), array([131, 132, 133, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[119, 122, 177, 176]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[117, 129, 182, 171]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[119, 122, 177, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675461.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 310

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 97, 114, 203, 186]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 98,  98,  98, ..., 200, 200, 200]), array([155, 156, 157, ..., 146, 147, 148]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 96,  98, 203, 200]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 97, 114, 203, 186]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 96,  98, 203, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947937.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 311

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 91,  64, 209, 235]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 83,  83,  83, ..., 221, 222, 223]), array([158, 159, 160, ..., 162, 106, 106]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 86,  83, 200, 223]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 91,  64, 209, 235]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 86,  83, 200, 223]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999537.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 312

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[ 96,  90, 203, 210]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 79,  79,  79, ..., 224, 224, 224]), array([106, 107, 108, ..., 193, 194, 195]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 84,  79, 216, 224]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[ 96,  90, 203, 210]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 84,  79, 216, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679968.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 313

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[120, 112, 179, 187]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([122, 122, 122, ..., 183, 183, 183]), array([134, 135, 136, ..., 166, 167, 168]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[127, 122, 176, 183]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[120, 112, 179, 187]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[127, 122, 176, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104739.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 314

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[138, 140, 161, 160]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([146, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 157, 157, 157, 157, 157]), array([147, 148, 149, 150, 151, 152, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 145, 146, 147, 148, 149, 150, 151, 152, 153, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 146, 147, 148, 149, 150]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[143, 146, 154, 157]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[138, 140, 161, 160]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[143, 146, 154, 157]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013912.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 315

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[116, 113, 184, 186]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([118, 118, 118, ..., 181, 181, 181]), array([126, 127, 128, ..., 170, 171, 172]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[118, 118, 184, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[116, 113, 184, 186]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[118, 118, 184, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434558.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 316

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[108, 101, 192, 198]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([107, 107, 107, ..., 203, 203, 203]), array([116, 117, 118, ..., 134, 135, 136]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[104, 107, 201, 203]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[108, 101, 192, 198]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[104, 107, 201, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501097029.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 317

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[102, 118, 197, 182]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([121, 121, 121, ..., 185, 185, 185]), array([143, 144, 145, ..., 174, 175, 176]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 99, 121, 188, 185]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[102, 118, 197, 182]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 99, 121, 188, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671369.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 318

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[132, 134, 167, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([131, 131, 131, ..., 166, 166, 166]), array([141, 142, 143, ..., 154, 155, 156]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[131, 131, 166, 166]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[132, 134, 167, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[131, 131, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775291.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 319

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 1
original_target_boxes: tensor([[132, 134, 168, 165]])
original_target_labels: tensor([1])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,
       135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 136, 136, 136,
       136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,
       137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,
       138, 138, 138, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,
       139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
       140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,
       141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,
       142, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,
       143, 143, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,
       145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,
       146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,
       147, 147, 147, 147, 147, 147, 147, 147, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,
       148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,
       149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,
       150, 150, 150, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,
       151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152,
       152, 152, 152, 152, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153,
       153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,
       154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155,
       155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156,
       156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158, 158,
       158, 158, 158, 158, 158, 158, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,
       159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160,
       160, 160, 160, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161,
       161, 161, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162,
       162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,
       163, 163, 163, 163, 163, 163, 163, 163, 163, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164,
       164, 164, 164, 164, 164, 164, 164, 164, 165, 165, 165, 165, 165,
       165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165, 165,
       165]), array([141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138,
       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,
       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,
       165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,
       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,
       158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137,
       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,
       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,
       164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135, 136,
       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,
       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,
       163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140, 141,
       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,
       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133, 134,
       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,
       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,
       161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 133,
       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,
       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,
       160, 161, 162, 163, 164, 165, 133, 134, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,
       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,
       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,
       159, 160, 161, 162, 163, 164, 134, 135, 136, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 134, 135,
       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,
       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,
       162, 163, 164, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157, 158, 159, 160, 161, 162, 163, 164, 135, 136, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 137, 138, 139,
       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,
       153, 154, 155, 156, 157, 158, 159, 160, 161, 137, 138, 139, 140,
       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
       154, 155, 156, 157, 158, 159, 160, 161, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,
       157]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[133, 135, 165, 165]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[132, 134, 168, 165]]), 'labels': tensor([1])}]
new_predicteds: [{'boxes': tensor([[133, 135, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013962.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 320

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 5
original_target_boxes: tensor([[107, 104, 193, 195]])
original_target_labels: tensor([5])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([ 95,  95,  95, ..., 212, 212, 212]), array([107, 108, 109, ..., 135, 136, 137]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[ 95,  95, 197, 212]])
predicted_scores: tensor([1])
predicted_labels: tensor([5])
new_targets: [{'boxes': tensor([[107, 104, 193, 195]]), 'labels': tensor([5])}]
new_predicteds: [{'boxes': tensor([[ 95,  95, 197, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530731203.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 321

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[116, 118, 183, 182]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([114, 114, 114, ..., 181, 181, 181]), array([118, 119, 120, ..., 132, 133, 134]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112, 114, 187, 181]])
predicted_scores: tensor([1])
predicted_labels: tensor([1])
new_targets: [{'boxes': tensor([[116, 118, 183, 182]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[112, 114, 187, 181]]), 'scores': tensor([1]), 'labels': tensor([1])}]
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434806.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 322

sampled_batch["image"].shape: torch.Size([1, 1, 3, 300, 300])
sampled_batch["image"].size()[2:]): torch.Size([3, 300, 300])
len(sampled_batch["image"].shape.size()[2:]): 3
h:3 w:300 channels:300
test_single_image_white_mold
001 - len(image.shape): 4
002 - image.shape: (1, 3, 300, 300)

inferencing image.shape not equal 3
len(image.shape): 4
image.shape 01: (1, 3, 300, 300)
x:300  y:300
scale: (1, 1, 0.7466666666666667, 0.7466666666666667)
image.shape 02: (1, 3, 300, 300)
image.shape 03: (1, 3, 224, 224)
input.shape: torch.Size([1, 3, 224, 224])
outputs.shape: torch.Size([1, 8, 224, 224])
out.shape: torch.Size([224, 224])
prediction.shape: (300, 300)
prediction: [[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
class_id: 3
original_target_boxes: tensor([[110, 105, 189, 195]])
original_target_labels: tensor([3])
classes: 8
prediction.shape: (300, 300)
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([103, 103, 103, ..., 195, 195, 195]), array([122, 123, 124, ..., 171, 172, 173]))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
prediction_image.shape: (300, 300)
segmentation: (array([], dtype=int64), array([], dtype=int64))
predicted_boxes: tensor([[112, 103, 187, 195]])
predicted_scores: tensor([1])
predicted_labels: tensor([3])
new_targets: [{'boxes': tensor([[110, 105, 189, 195]]), 'labels': tensor([3])}]
new_predicteds: [{'boxes': tensor([[112, 103, 187, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
001 normalized_image.shape: (300, 300, 3)
002 normalized_image.shape: (1, 300, 300, 3)
003 normalized_image.shape: torch.Size([1, 3, 300, 300])
004 label.shape: (300, 300)
path_and_original_rgb_image_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-dataset/results-pre-processed-images/running-0021-15ds-300x300-merged-classes/splitting_by_images/4-balanced-output-dataset/mask-image/test/ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434769.jpg
original_rgb_image.shape: (300, 300, 3)
test.py - inference_metric: 
Metrics

len(self.inferenced_images): 323

metrics_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/metrics

Computing Confusion Matrix

 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785691.jpg', 'targets_list': [{'boxes': tensor([[135, 131, 165, 168]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[135, 137, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[135, 131, 165, 168]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[135, 137, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1500526739.jpg', 'targets_list': [{'boxes': tensor([[109, 106, 191, 193]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[108, 108, 191, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[109, 106, 191, 193]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[108, 108, 191, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3979-bbox-1533656590.jpg', 'targets_list': [{'boxes': tensor([[106, 112, 193, 188]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[110, 110, 189, 193]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[106, 112, 193, 188]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[110, 110, 189, 193]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797254.jpg', 'targets_list': [{'boxes': tensor([[141, 138, 158, 161]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[141, 138, 158, 161]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212058.jpg', 'targets_list': [{'boxes': tensor([[116,  81, 184, 218]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 99,  86, 208, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[116,  81, 184, 218]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 99,  86, 208, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533752.jpg', 'targets_list': [{'boxes': tensor([[129, 133, 170, 167]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[126, 126, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[129, 133, 170, 167]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[126, 126, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434568.jpg', 'targets_list': [{'boxes': tensor([[ 99, 123, 201, 177]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[107, 123, 193, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 99, 123, 201, 177]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[107, 123, 193, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332475.jpg', 'targets_list': [{'boxes': tensor([[118, 120, 181, 179]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[112, 111, 185, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[118, 120, 181, 179]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[112, 111, 185, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135678.jpg', 'targets_list': [{'boxes': tensor([[130, 121, 170, 178]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[118, 119, 177, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[130, 121, 170, 178]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[118, 119, 177, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947686.jpg', 'targets_list': [{'boxes': tensor([[ 91,  75, 208, 225]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 86,  74, 219, 229]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 91,  75, 208, 225]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 86,  74, 219, 229]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748029.jpg', 'targets_list': [{'boxes': tensor([[130, 129, 170, 170]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[130, 134, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[130, 129, 170, 170]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[130, 134, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610356.jpg', 'targets_list': [{'boxes': tensor([[117, 124, 182, 175]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[118, 127, 176, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[117, 124, 182, 175]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[118, 127, 176, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797053.jpg', 'targets_list': [{'boxes': tensor([[141, 137, 159, 162]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 79, 115, 192, 191]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[141, 137, 159, 162]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 79, 115, 192, 191]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211850.jpg', 'targets_list': [{'boxes': tensor([[116, 119, 183, 180]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 122, 183, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[116, 119, 183, 180]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 122, 183, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796994.jpg', 'targets_list': [{'boxes': tensor([[140, 136, 159, 164]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 121, 183, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[140, 136, 159, 164]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 121, 183, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818813.jpg', 'targets_list': [{'boxes': tensor([[120, 129, 179, 170]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[104, 102, 192, 181]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[120, 129, 179, 170]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[104, 102, 192, 181]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930897.jpg', 'targets_list': [{'boxes': tensor([[120, 113, 180, 187]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[116, 110, 181, 188]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[120, 113, 180, 187]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[116, 110, 181, 188]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096986.jpg', 'targets_list': [{'boxes': tensor([[122,  96, 178, 203]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[126, 121, 169, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[122,  96, 178, 203]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[126, 121, 169, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-02-fazenda-vs-pivo-06-IMG_2875-bbox-1529999100.jpg', 'targets_list': [{'boxes': tensor([[ 79, 138, 153, 202]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 80,  94, 212, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 79, 138, 153, 202]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 80,  94, 212, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212091.jpg', 'targets_list': [{'boxes': tensor([[114, 106, 186, 194]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[115, 100, 185, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[114, 106, 186, 194]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[115, 100, 185, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-03-pivo-03-20230930_123113-bbox-1429245310.jpg', 'targets_list': [{'boxes': tensor([[122, 118, 178, 182]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[125, 125, 174, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[122, 118, 178, 182]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[125, 125, 174, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604248.jpg', 'targets_list': [{'boxes': tensor([[ 98,  99, 202, 201]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[ 96, 102, 195, 201]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[ 98,  99, 202, 201]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[ 96, 102, 195, 201]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161557-bbox-1415718287.jpg', 'targets_list': [{'boxes': tensor([[136, 134, 163, 166]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[135, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 134, 163, 166]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[135, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775271.jpg', 'targets_list': [{'boxes': tensor([[129, 131, 171, 169]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[131, 131, 169, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[129, 131, 171, 169]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[131, 131, 169, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776103.jpg', 'targets_list': [{'boxes': tensor([[136, 135, 164, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[135, 135, 164, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 135, 164, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[135, 135, 164, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533791.jpg', 'targets_list': [{'boxes': tensor([[129, 120, 170, 180]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[134, 142, 169, 177],
        [130, 125, 170, 170]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]}

targets: [{'boxes': tensor([[129, 120, 170, 180]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[134, 142, 169, 177],
        [130, 125, 170, 170]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013908.jpg', 'targets_list': [{'boxes': tensor([[123, 119, 176, 180]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[123, 125, 176, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[123, 119, 176, 180]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[123, 125, 176, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160508-bbox-1411007689.jpg', 'targets_list': [{'boxes': tensor([[122, 123, 177, 177]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[123, 125, 176, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[122, 123, 177, 177]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[123, 125, 176, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120312-bbox-1533675660.jpg', 'targets_list': [{'boxes': tensor([[132, 129, 168, 170]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[129, 127, 173, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[132, 129, 168, 170]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[129, 127, 173, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4519-bbox-1533833204.jpg', 'targets_list': [{'boxes': tensor([[121, 128, 179, 171]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[122, 126, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[121, 128, 179, 171]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[122, 126, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675469.jpg', 'targets_list': [{'boxes': tensor([[126, 115, 174, 184]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 126, 170, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[126, 115, 174, 184]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 126, 170, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679961.jpg', 'targets_list': [{'boxes': tensor([[ 93,  97, 206, 203]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 94,  84, 209, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 93,  97, 206, 203]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 94,  84, 209, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451613.jpg', 'targets_list': [{'boxes': tensor([[110,  99, 190, 201]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[104, 112, 193, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[110,  99, 190, 201]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[104, 112, 193, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2530-bbox-1505679998.jpg', 'targets_list': [{'boxes': tensor([[ 92,  76, 207, 224]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 83,  68, 212, 231]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 92,  76, 207, 224]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 83,  68, 212, 231]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675467.jpg', 'targets_list': [{'boxes': tensor([[126, 119, 174, 180]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[126, 125, 174, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[126, 119, 174, 180]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[126, 125, 174, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2528-bbox-1505667180.jpg', 'targets_list': [{'boxes': tensor([[104, 114, 195, 185]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[104, 108, 203, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[104, 114, 195, 185]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[104, 108, 203, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078097.jpg', 'targets_list': [{'boxes': tensor([[130, 103, 170, 197]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[129, 126, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[130, 103, 170, 197]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[129, 126, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1804-bbox-1524227328.jpg', 'targets_list': [{'boxes': tensor([[116, 122, 184, 177]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[118, 119, 184, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[116, 122, 184, 177]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[118, 119, 184, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930918.jpg', 'targets_list': [{'boxes': tensor([[112, 121, 187, 178]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[123, 129, 176, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[112, 121, 187, 178]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[123, 129, 176, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743250.jpg', 'targets_list': [{'boxes': tensor([[123,  90, 177, 210]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[126, 126, 170, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[123,  90, 177, 210]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[126, 126, 170, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013917.jpg', 'targets_list': [{'boxes': tensor([[126, 133, 173, 166]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 130, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[126, 133, 173, 166]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 130, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092113-bbox-1418087509.jpg', 'targets_list': [{'boxes': tensor([[135, 135, 165, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[134, 135, 164, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[135, 135, 165, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[134, 135, 164, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2798-bbox-1531448008.jpg', 'targets_list': [{'boxes': tensor([[138, 132, 161, 167]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[137, 135, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[138, 132, 161, 167]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[137, 135, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445789.jpg', 'targets_list': [{'boxes': tensor([[131, 138, 154, 161]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 131, 164, 168]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[131, 138, 154, 161]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 131, 164, 168]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610377.jpg', 'targets_list': [{'boxes': tensor([[126, 116, 174, 184]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[125, 116, 178, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[126, 116, 174, 184]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[125, 116, 178, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785699.jpg', 'targets_list': [{'boxes': tensor([[122, 124, 178, 176]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[126, 127, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[122, 124, 178, 176]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[126, 127, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_162248-bbox-1416067564.jpg', 'targets_list': [{'boxes': tensor([[124, 124, 175, 176]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[125, 125, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[124, 124, 175, 176]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[125, 125, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604258.jpg', 'targets_list': [{'boxes': tensor([[104, 109, 196, 190]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[100, 106, 199, 193]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[104, 109, 196, 190]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[100, 106, 199, 193]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_163521-bbox-1529526422.jpg', 'targets_list': [{'boxes': tensor([[104,  88, 196, 212]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 82,  94, 219, 209]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[104,  88, 196, 212]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 82,  94, 219, 209]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_135337-bbox-1407347421.jpg', 'targets_list': [{'boxes': tensor([[139, 137, 161, 162]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 137, 162, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[139, 137, 161, 162]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 137, 162, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015009.jpg', 'targets_list': [{'boxes': tensor([[130, 127, 170, 173]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[129, 127, 170, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[130, 127, 170, 173]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[129, 127, 170, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105404.jpg', 'targets_list': [{'boxes': tensor([[ 65,  68, 234, 231]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 55,  70, 233, 229]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 65,  68, 234, 231]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 55,  70, 233, 229]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434579.jpg', 'targets_list': [{'boxes': tensor([[112, 114, 187, 185]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[108, 110, 188, 185]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[112, 114, 187, 185]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[108, 110, 188, 185]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014504.jpg', 'targets_list': [{'boxes': tensor([[133, 134, 166, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[133, 134, 166, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947677.jpg', 'targets_list': [{'boxes': tensor([[100,  94, 200, 206]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[112, 110, 187, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[100,  94, 200, 206]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[112, 110, 187, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776168.jpg', 'targets_list': [{'boxes': tensor([[207, 121, 266, 178]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[115, 129, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[207, 121, 266, 178]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[115, 129, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524765.jpg', 'targets_list': [{'boxes': tensor([[129, 130, 170, 169]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[129, 130, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[129, 130, 170, 169]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[129, 130, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001608.jpg', 'targets_list': [{'boxes': tensor([[107, 105, 192, 194]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[107,  94, 201, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[107, 105, 192, 194]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[107,  94, 201, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2477-bbox-1503748285.jpg', 'targets_list': [{'boxes': tensor([[101, 112, 199, 187]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 96, 106, 207, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[101, 112, 199, 187]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 96, 106, 207, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1897-bbox-1519483072.jpg', 'targets_list': [{'boxes': tensor([[138, 138, 161, 162]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[146, 150, 152, 154]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[138, 138, 161, 162]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[146, 150, 152, 154]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527536645.jpg', 'targets_list': [{'boxes': tensor([[122, 126, 178, 173]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[137, 139, 153, 158]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[122, 126, 178, 173]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[137, 139, 153, 158]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112354-bbox-1417775833.jpg', 'targets_list': [{'boxes': tensor([[140, 140, 159, 160]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[138, 138, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[140, 140, 159, 160]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[138, 138, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012704.jpg', 'targets_list': [{'boxes': tensor([[136, 136, 163, 164]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[135, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 136, 163, 164]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[135, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524443.jpg', 'targets_list': [{'boxes': tensor([[125, 127, 175, 173]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 116, 185, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[125, 127, 175, 173]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 116, 185, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947725.jpg', 'targets_list': [{'boxes': tensor([[ 97, 102, 202, 198]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[100, 115, 193, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 97, 102, 202, 198]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[100, 115, 193, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-02-fazenda-vs-pivo-06-IMG_2875-bbox-1529999102.jpg', 'targets_list': [{'boxes': tensor([[100, 130, 200, 170]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[100, 110, 196, 187]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[100, 130, 200, 170]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[100, 110, 196, 187]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478590.jpg', 'targets_list': [{'boxes': tensor([[130, 132, 169, 168]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[129, 129, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[130, 132, 169, 168]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[129, 129, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748053.jpg', 'targets_list': [{'boxes': tensor([[127, 128, 172, 171]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 95, 115, 197, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[127, 128, 172, 171]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 95, 115, 197, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014510.jpg', 'targets_list': [{'boxes': tensor([[138, 137, 162, 162]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[138, 137, 162, 162]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348197.jpg', 'targets_list': [{'boxes': tensor([[129, 130, 170, 169]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 129, 169, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[129, 130, 170, 169]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 129, 169, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3928-bbox-1531429137.jpg', 'targets_list': [{'boxes': tensor([[ 74,  63, 226, 236]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 68,  64, 228, 239]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 74,  63, 226, 236]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 68,  64, 228, 239]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227985.jpg', 'targets_list': [{'boxes': tensor([[126, 103, 174, 196]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[125, 122, 174, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[126, 103, 174, 196]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[125, 122, 174, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652326.jpg', 'targets_list': [{'boxes': tensor([[100, 106, 199, 193]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 96, 106, 205, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[100, 106, 199, 193]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 96, 106, 205, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_111804-bbox-1416831265.jpg', 'targets_list': [{'boxes': tensor([[137, 138, 163, 161]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[137, 138, 163, 161]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2482-bbox-1504140817.jpg', 'targets_list': [{'boxes': tensor([[115,  94, 184, 205]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[112,  96, 184, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[115,  94, 184, 205]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[112,  96, 184, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001614.jpg', 'targets_list': [{'boxes': tensor([[119, 115, 181, 184]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[114, 118, 181, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[119, 115, 181, 184]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[114, 118, 181, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013963.jpg', 'targets_list': [{'boxes': tensor([[124, 123, 176, 177]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[125, 125, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[124, 123, 176, 177]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[125, 125, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013875.jpg', 'targets_list': [{'boxes': tensor([[136, 134, 163, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 134, 163, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 137, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451492.jpg', 'targets_list': [{'boxes': tensor([[ 99, 116, 200, 183]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 79, 114, 215, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 99, 116, 200, 183]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 79, 114, 215, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2562-bbox-1506386836.jpg', 'targets_list': [{'boxes': tensor([[108,  92, 191, 208]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[108, 100, 188, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[108,  92, 191, 208]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[108, 100, 188, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161627-bbox-1415718393.jpg', 'targets_list': [{'boxes': tensor([[126, 130, 173, 170]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[129, 130, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[126, 130, 173, 170]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[129, 130, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524795.jpg', 'targets_list': [{'boxes': tensor([[134, 130, 166, 170]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[133, 133, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[134, 130, 166, 170]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[133, 133, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102985.jpg', 'targets_list': [{'boxes': tensor([[129, 133, 170, 167]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[131, 135, 164, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[129, 133, 170, 167]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[131, 135, 164, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078086.jpg', 'targets_list': [{'boxes': tensor([[132, 122, 168, 178]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[134, 135, 164, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[132, 122, 168, 178]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[134, 135, 164, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527544133.jpg', 'targets_list': [{'boxes': tensor([[ 94,  88, 205, 211]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[103, 103, 197, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 94,  88, 205, 211]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[103, 103, 197, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012707.jpg', 'targets_list': [{'boxes': tensor([[133, 131, 166, 168]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 131, 166, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[133, 131, 166, 168]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 131, 166, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_162248-bbox-1416067575.jpg', 'targets_list': [{'boxes': tensor([[114, 106, 186, 194]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[106, 104, 191, 195]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[114, 106, 186, 194]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[106, 104, 191, 195]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500499785.jpg', 'targets_list': [{'boxes': tensor([[ 66,  39, 233, 260]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 79,  74, 224, 219]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 66,  39, 233, 260]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 79,  74, 224, 219]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604276.jpg', 'targets_list': [{'boxes': tensor([[ 85,  73, 214, 226]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[ 70,  71, 225, 229]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[ 85,  73, 214, 226]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[ 70,  71, 225, 229]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930921.jpg', 'targets_list': [{'boxes': tensor([[ 96,  82, 204, 218]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 92,  84, 203, 225]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 96,  82, 204, 218]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 92,  84, 203, 225]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652330.jpg', 'targets_list': [{'boxes': tensor([[ 98,  94, 201, 205]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 95,  92, 205, 213]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 98,  94, 201, 205]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 95,  92, 205, 213]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_135136-bbox-1407347318.jpg', 'targets_list': [{'boxes': tensor([[ 85,  83, 214, 216]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[ 86,  82, 216, 215]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[ 85,  83, 214, 216]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[ 86,  82, 216, 215]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135702.jpg', 'targets_list': [{'boxes': tensor([[120, 125, 179, 174]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[118, 125, 180, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[120, 125, 179, 174]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[118, 125, 180, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743234.jpg', 'targets_list': [{'boxes': tensor([[106, 113, 194, 187]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[108, 102, 189, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[106, 113, 194, 187]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[108, 102, 189, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947984.jpg', 'targets_list': [{'boxes': tensor([[ 74, 109, 225, 191]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 76,  70, 221, 219]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 74, 109, 225, 191]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 76,  70, 221, 219]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500495896.jpg', 'targets_list': [{'boxes': tensor([[113,  78, 186, 221]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 94,  60, 208, 239]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[113,  78, 186, 221]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 94,  60, 208, 239]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434714.jpg', 'targets_list': [{'boxes': tensor([[132, 126, 168, 174]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[126, 123, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[132, 126, 168, 174]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[126, 123, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775298.jpg', 'targets_list': [{'boxes': tensor([[131, 132, 169, 167]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[131, 132, 169, 167]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818829.jpg', 'targets_list': [{'boxes': tensor([[127, 127, 173, 173]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[114, 127, 177, 184],
        [137, 126, 174, 141]]), 'scores': tensor([1, 1]), 'labels': tensor([1, 3])}]}

targets: [{'boxes': tensor([[127, 127, 173, 173]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[114, 127, 177, 184],
        [137, 126, 174, 141]]), 'scores': tensor([1, 1]), 'labels': tensor([1, 3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530730668.jpg', 'targets_list': [{'boxes': tensor([[ 95, 108, 205, 191]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 96, 104, 195, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 95, 108, 205, 191]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 96, 104, 195, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797021.jpg', 'targets_list': [{'boxes': tensor([[134, 128, 165, 172]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 125, 169, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[134, 128, 165, 172]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 125, 169, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775232.jpg', 'targets_list': [{'boxes': tensor([[120, 122, 179, 177]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[123, 125, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[120, 122, 179, 177]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[123, 125, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1967-bbox-1500168559.jpg', 'targets_list': [{'boxes': tensor([[102,  89, 198, 210]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[111, 106, 193, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[102,  89, 198, 210]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[111, 106, 193, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679959.jpg', 'targets_list': [{'boxes': tensor([[103, 116, 196, 184]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[104, 107, 200, 193]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[103, 116, 196, 184]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[104, 107, 200, 193]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104752.jpg', 'targets_list': [{'boxes': tensor([[119, 118, 181, 182]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[123, 122, 180, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[119, 118, 181, 182]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[123, 122, 180, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530725274.jpg', 'targets_list': [{'boxes': tensor([[ 84, 118, 215, 182]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 82,  79, 215, 216]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 84, 118, 215, 182]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 82,  79, 215, 216]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104720.jpg', 'targets_list': [{'boxes': tensor([[122, 120, 177, 179]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[123, 118, 174, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[122, 120, 177, 179]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[123, 118, 174, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096983.jpg', 'targets_list': [{'boxes': tensor([[ 97,  90, 202, 210]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 95,  94, 200, 209]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 97,  90, 202, 210]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 95,  94, 200, 209]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530731602.jpg', 'targets_list': [{'boxes': tensor([[114, 111, 186, 188]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 94,  94, 204, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[114, 111, 186, 188]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 94,  94, 204, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999543.jpg', 'targets_list': [{'boxes': tensor([[107, 112, 192, 188]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[102,  76, 200, 231]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[107, 112, 192, 188]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[102,  76, 200, 231]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527535109.jpg', 'targets_list': [{'boxes': tensor([[127, 116, 172, 184]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[131, 119, 168, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[127, 116, 172, 184]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[131, 119, 168, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2478-bbox-1503748392.jpg', 'targets_list': [{'boxes': tensor([[125, 117, 175, 183]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[122, 122, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[125, 117, 175, 183]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[122, 122, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_110955-bbox-1416788230.jpg', 'targets_list': [{'boxes': tensor([[131, 133, 169, 167]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[134, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[131, 133, 169, 167]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[134, 134, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104769.jpg', 'targets_list': [{'boxes': tensor([[106, 118, 193, 182]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 99, 107, 191, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[106, 118, 193, 182]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 99, 107, 191, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105411.jpg', 'targets_list': [{'boxes': tensor([[ 72, 100, 227, 200]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 64,  91, 236, 208]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 72, 100, 227, 200]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 64,  91, 236, 208]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3633-bbox-1506586882.jpg', 'targets_list': [{'boxes': tensor([[ 56,  85, 244, 215]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 66,  86, 233, 213]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 56,  85, 244, 215]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 66,  86, 233, 213]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604268.jpg', 'targets_list': [{'boxes': tensor([[113, 118, 186, 206]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[108, 107, 189, 204]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[113, 118, 186, 206]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[108, 107, 189, 204]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013907.jpg', 'targets_list': [{'boxes': tensor([[134, 135, 165, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[135, 135, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[134, 135, 165, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[135, 135, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434827.jpg', 'targets_list': [{'boxes': tensor([[ 62,  78, 238, 221]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 62,  66, 240, 221]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 62,  78, 238, 221]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 62,  66, 240, 221]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785712.jpg', 'targets_list': [{'boxes': tensor([[127, 130, 172, 169]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 130, 170, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[127, 130, 172, 169]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 130, 170, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879143.jpg', 'targets_list': [{'boxes': tensor([[ 75, 141,  91, 159]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[ 75, 141,  91, 159]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_163521-bbox-1529526130.jpg', 'targets_list': [{'boxes': tensor([[111,  96, 189, 203]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[111, 104, 188, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[111,  96, 189, 203]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[111, 104, 188, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1967-bbox-1500168166.jpg', 'targets_list': [{'boxes': tensor([[105, 104, 194, 195]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[116, 111, 185, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[105, 104, 194, 195]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[116, 111, 185, 180]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999521.jpg', 'targets_list': [{'boxes': tensor([[120, 113, 179, 187]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[102, 107, 199, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[120, 113, 179, 187]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[102, 107, 199, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540438.jpg', 'targets_list': [{'boxes': tensor([[123, 102, 176, 197]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[137, 133, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[123, 102, 176, 197]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[137, 133, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104735.jpg', 'targets_list': [{'boxes': tensor([[ 67,  92, 233, 208]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 67,  90, 232, 215]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 67,  92, 233, 208]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 67,  90, 232, 215]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135726.jpg', 'targets_list': [{'boxes': tensor([[120, 123, 180, 177]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 116, 180, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[120, 123, 180, 177]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 116, 180, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3930-bbox-1531429402.jpg', 'targets_list': [{'boxes': tensor([[ 86, 107, 214, 192]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 95, 102, 199, 196]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 86, 107, 214, 192]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 95, 102, 199, 196]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_164849-bbox-1530658464.jpg', 'targets_list': [{'boxes': tensor([[116, 109, 183, 191]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 79,  88, 223, 211]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[116, 109, 183, 191]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 79,  88, 223, 211]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2579-bbox-1499560953.jpg', 'targets_list': [{'boxes': tensor([[139, 141, 160, 158]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[150, 149, 153, 152]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[139, 141, 160, 158]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[150, 149, 153, 152]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585146.jpg', 'targets_list': [{'boxes': tensor([[123, 115, 176, 185]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[122, 115, 180, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[123, 115, 176, 185]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[122, 115, 180, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105427.jpg', 'targets_list': [{'boxes': tensor([[ 62,  97, 238, 203]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[100,  99, 209, 215]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 62,  97, 238, 203]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[100,  99, 209, 215]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743231.jpg', 'targets_list': [{'boxes': tensor([[ 98, 111, 201, 188]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[114, 111, 180, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 98, 111, 201, 188]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[114, 111, 180, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212093.jpg', 'targets_list': [{'boxes': tensor([[129, 117, 170, 183]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 96, 103, 193, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[129, 117, 170, 183]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 96, 103, 193, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534091011.jpg', 'targets_list': [{'boxes': tensor([[140, 139, 159, 160]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[142, 134, 157, 154]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[140, 139, 159, 160]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[142, 134, 157, 154]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078092.jpg', 'targets_list': [{'boxes': tensor([[114,  99, 186, 200]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[119, 110, 184, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[114,  99, 186, 200]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[119, 110, 184, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930912.jpg', 'targets_list': [{'boxes': tensor([[132, 134, 167, 166]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[131, 133, 169, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[132, 134, 167, 166]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[131, 133, 169, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2475-bbox-1503748166.jpg', 'targets_list': [{'boxes': tensor([[124, 128, 176, 172]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[122, 126, 178, 174]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[124, 128, 176, 172]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[122, 126, 178, 174]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1884-bbox-1519001508.jpg', 'targets_list': [{'boxes': tensor([[130, 121, 169, 179]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[118, 119, 173, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[130, 121, 169, 179]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[118, 119, 173, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999530.jpg', 'targets_list': [{'boxes': tensor([[107,  85, 192, 215]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[111, 100, 178, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[107,  85, 192, 215]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[111, 100, 178, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112354-bbox-1417775811.jpg', 'targets_list': [{'boxes': tensor([[132, 131, 167, 168]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 131, 168, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[132, 131, 167, 168]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 131, 168, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2530-bbox-1505679995.jpg', 'targets_list': [{'boxes': tensor([[102,  97, 198, 202]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 98, 102, 195, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[102,  97, 198, 202]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 98, 102, 195, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451419.jpg', 'targets_list': [{'boxes': tensor([[ 73, 103, 226, 196]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 78,  91, 215, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 73, 103, 226, 196]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 78,  91, 215, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096987.jpg', 'targets_list': [{'boxes': tensor([[110,  96, 189, 203]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[114, 106, 181, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[110,  96, 189, 203]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[114, 106, 181, 195]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015014.jpg', 'targets_list': [{'boxes': tensor([[135, 135, 164, 165]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[135, 134, 164, 165]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[135, 135, 164, 165]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[135, 134, 164, 165]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2482-bbox-1504140857.jpg', 'targets_list': [{'boxes': tensor([[124, 119, 175, 180]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[121, 119, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[124, 119, 175, 180]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[121, 119, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999519.jpg', 'targets_list': [{'boxes': tensor([[109,  90, 191, 210]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[109,  90, 191, 210]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013909.jpg', 'targets_list': [{'boxes': tensor([[129, 129, 171, 171]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 131, 168, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[129, 129, 171, 171]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 131, 168, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675464.jpg', 'targets_list': [{'boxes': tensor([[125, 118, 174, 182]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[125, 122, 174, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[125, 118, 174, 182]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[125, 122, 174, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500499770.jpg', 'targets_list': [{'boxes': tensor([[ 88,  82, 212, 218]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 79,  68, 236, 228]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 88,  82, 212, 218]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 79,  68, 236, 228]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1887-bbox-1519014865.jpg', 'targets_list': [{'boxes': tensor([[101,  76, 199, 223]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 82,  74, 204, 232]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[101,  76, 199, 223]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 82,  74, 204, 232]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141463.jpg', 'targets_list': [{'boxes': tensor([[108, 116, 191, 183]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 96, 110, 205, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[108, 116, 191, 183]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 96, 110, 205, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775492.jpg', 'targets_list': [{'boxes': tensor([[129, 124, 171, 175]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[126, 129, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[129, 124, 171, 175]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[126, 129, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999544.jpg', 'targets_list': [{'boxes': tensor([[101,  78, 198, 222]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 91,  88, 193, 211]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[101,  78, 198, 222]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 91,  88, 193, 211]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2452-bbox-1503652385.jpg', 'targets_list': [{'boxes': tensor([[ 42,  84, 258, 215]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 40,  67, 255, 225]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 42,  84, 258, 215]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 40,  67, 255, 225]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534090915.jpg', 'targets_list': [{'boxes': tensor([[137, 139, 163, 160]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[135, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[137, 139, 163, 160]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[135, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879141.jpg', 'targets_list': [{'boxes': tensor([[135, 137, 164, 162]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[133, 134, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[135, 137, 164, 162]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[133, 134, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748045.jpg', 'targets_list': [{'boxes': tensor([[102,  98, 198, 201]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[118, 119, 187, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[102,  98, 198, 201]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[118, 119, 187, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539856.jpg', 'targets_list': [{'boxes': tensor([[117, 119, 182, 181]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[122, 121, 180, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[117, 119, 182, 181]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[122, 121, 180, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030577.jpg', 'targets_list': [{'boxes': tensor([[113, 101, 186, 198]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[112, 104, 183, 196]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[113, 101, 186, 198]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[112, 104, 183, 196]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947644.jpg', 'targets_list': [{'boxes': tensor([[104,  95, 195, 205]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 91, 100, 203, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[104,  95, 195, 205]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 91, 100, 203, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434586.jpg', 'targets_list': [{'boxes': tensor([[104, 115, 196, 185]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 95, 111, 201, 189]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[104, 115, 196, 185]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 95, 111, 201, 189]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211899.jpg', 'targets_list': [{'boxes': tensor([[138, 123, 162, 176]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[133, 131, 166, 172]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[138, 123, 162, 176]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[133, 131, 166, 172]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030606.jpg', 'targets_list': [{'boxes': tensor([[ 80,  77, 219, 223]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 84,  91, 120, 118],
        [ 90,  87, 204, 212]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]}

targets: [{'boxes': tensor([[ 80,  77, 219, 223]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 84,  91, 120, 118],
        [ 90,  87, 204, 212]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095137-bbox-1500962989.jpg', 'targets_list': [{'boxes': tensor([[102,  87, 197, 212]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[111, 104, 181, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[102,  87, 197, 212]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[111, 104, 181, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748040.jpg', 'targets_list': [{'boxes': tensor([[110, 106, 189, 194]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[110, 114, 188, 193]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[110, 106, 189, 194]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[110, 114, 188, 193]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539646.jpg', 'targets_list': [{'boxes': tensor([[108,  94, 191, 206]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[118,  96, 181, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[108,  94, 191, 206]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[118,  96, 181, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102979.jpg', 'targets_list': [{'boxes': tensor([[125, 128, 174, 172]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[129, 133, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[125, 128, 174, 172]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[129, 133, 166, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227961.jpg', 'targets_list': [{'boxes': tensor([[123, 124, 176, 175]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[126, 126, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[123, 124, 176, 175]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[126, 126, 174, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1876-bbox-1518941256.jpg', 'targets_list': [{'boxes': tensor([[108,  99, 191, 200]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[116, 115, 184, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[108,  99, 191, 200]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[116, 115, 184, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604272.jpg', 'targets_list': [{'boxes': tensor([[128, 128, 171, 172]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[127, 129, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[128, 128, 171, 172]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[127, 129, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_3901-bbox-1533822128.jpg', 'targets_list': [{'boxes': tensor([[ 90,  75, 210, 224]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 91,  95, 199, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 90,  75, 210, 224]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 91,  95, 199, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161634-bbox-1415718444.jpg', 'targets_list': [{'boxes': tensor([[114, 123, 186, 176]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[118, 123, 180, 176]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[114, 123, 186, 176]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[118, 123, 180, 176]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2598-bbox-1499561022.jpg', 'targets_list': [{'boxes': tensor([[131, 124, 169, 175]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[133, 129, 164, 168]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[131, 124, 169, 175]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[133, 129, 164, 168]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595384.jpg', 'targets_list': [{'boxes': tensor([[ 71,  94, 229, 205]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 80,  95, 217, 203]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 71,  94, 229, 205]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 80,  95, 217, 203]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014505.jpg', 'targets_list': [{'boxes': tensor([[139, 138, 161, 162]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 138, 162, 164]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[139, 138, 161, 162]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 138, 162, 164]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533753.jpg', 'targets_list': [{'boxes': tensor([[126, 126, 173, 174]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[125, 127, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[126, 126, 173, 174]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[125, 127, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539647.jpg', 'targets_list': [{'boxes': tensor([[117, 107, 183, 193]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[129, 122, 168, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[117, 107, 183, 193]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[129, 122, 168, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434612.jpg', 'targets_list': [{'boxes': tensor([[ 95, 102, 205, 198]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 92,  96, 203, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 95, 102, 205, 198]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 92,  96, 203, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671387.jpg', 'targets_list': [{'boxes': tensor([[127, 103, 172, 196]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 115, 170, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[127, 103, 172, 196]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 115, 170, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105414.jpg', 'targets_list': [{'boxes': tensor([[ 63,  45, 237, 254]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 78,  84, 237, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 63,  45, 237, 254]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 78,  84, 237, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604252.jpg', 'targets_list': [{'boxes': tensor([[ 88,  94, 211, 206]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[ 88,  90, 209, 212]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[ 88,  94, 211, 206]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[ 88,  90, 209, 212]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161634-bbox-1415718433.jpg', 'targets_list': [{'boxes': tensor([[127, 127, 173, 173]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[129, 129, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[127, 127, 173, 173]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[129, 129, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524305.jpg', 'targets_list': [{'boxes': tensor([[121, 123, 179, 177]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 122, 185, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[121, 123, 179, 177]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 122, 185, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1519910868.jpg', 'targets_list': [{'boxes': tensor([[114, 112, 185, 187]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[115, 115, 184, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[114, 112, 185, 187]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[115, 115, 184, 183]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673162.jpg', 'targets_list': [{'boxes': tensor([[118,  95, 182, 204]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 95,  96, 196, 207]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[118,  95, 182, 204]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 95,  96, 196, 207]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2766-bbox-1530054833.jpg', 'targets_list': [{'boxes': tensor([[136, 136, 164, 164]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 118, 176, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[136, 136, 164, 164]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 118, 176, 169]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533759.jpg', 'targets_list': [{'boxes': tensor([[135, 129, 165, 171]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[133, 131, 168, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[135, 129, 165, 171]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[133, 131, 168, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595385.jpg', 'targets_list': [{'boxes': tensor([[ 87,  66, 212, 233]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 74,  64, 227, 247]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 87,  66, 212, 233]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 74,  64, 227, 247]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4532-bbox-1533854039.jpg', 'targets_list': [{'boxes': tensor([[124, 121, 176, 179]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[129, 126, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[124, 121, 176, 179]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[129, 126, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604281.jpg', 'targets_list': [{'boxes': tensor([[129, 102, 171, 198]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 103, 217, 197],
        [127, 133, 157, 189]]), 'scores': tensor([1, 1]), 'labels': tensor([1, 3])}]}

targets: [{'boxes': tensor([[129, 102, 171, 198]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 103, 217, 197],
        [127, 133, 157, 189]]), 'scores': tensor([1, 1]), 'labels': tensor([1, 3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_094448-bbox-1418427497.jpg', 'targets_list': [{'boxes': tensor([[119, 121, 181, 179]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[118, 121, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[119, 121, 181, 179]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[118, 121, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227933.jpg', 'targets_list': [{'boxes': tensor([[118, 115, 181, 184]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[118, 116, 183, 181]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[118, 115, 181, 184]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[118, 116, 183, 181]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2562-bbox-1506386819.jpg', 'targets_list': [{'boxes': tensor([[131, 125, 169, 174]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[138, 131, 164, 164]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[131, 125, 169, 174]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[138, 131, 164, 164]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141461.jpg', 'targets_list': [{'boxes': tensor([[ 95, 101, 204, 199]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 94,  96, 211, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 95, 101, 204, 199]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 94,  96, 211, 207]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675948.jpg', 'targets_list': [{'boxes': tensor([[121, 123, 179, 176]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[122, 129, 166, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[121, 123, 179, 176]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[122, 129, 166, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530737130.jpg', 'targets_list': [{'boxes': tensor([[ 93,  98, 207, 202]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[103,  96, 200, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 93,  98, 207, 202]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[103,  96, 200, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_3901-bbox-1533822142.jpg', 'targets_list': [{'boxes': tensor([[106,  82, 194, 217]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 78,  79, 221, 221]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[106,  82, 194, 217]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 78,  79, 221, 221]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947869.jpg', 'targets_list': [{'boxes': tensor([[ 66,  77, 234, 223]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 72,  82, 220, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 66,  77, 234, 223]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 72,  82, 220, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540435.jpg', 'targets_list': [{'boxes': tensor([[120, 105, 180, 194]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[126, 123, 168, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[120, 105, 180, 194]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[126, 123, 168, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013877.jpg', 'targets_list': [{'boxes': tensor([[138, 139, 162, 161]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[138, 141, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[138, 139, 162, 161]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[138, 141, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534090997.jpg', 'targets_list': [{'boxes': tensor([[139, 139, 161, 161]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[138, 141, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[139, 139, 161, 161]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[138, 141, 160, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092252-bbox-1418298951.jpg', 'targets_list': [{'boxes': tensor([[133, 129, 167, 171]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 133, 166, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[133, 129, 167, 171]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 133, 166, 168]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332531.jpg', 'targets_list': [{'boxes': tensor([[123,  81, 177, 219]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[118, 100, 181, 196]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[123,  81, 177, 219]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[118, 100, 181, 196]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120314-bbox-1533675703.jpg', 'targets_list': [{'boxes': tensor([[107, 113, 192, 186]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[115, 116, 180, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[107, 113, 192, 186]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[115, 116, 180, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014507.jpg', 'targets_list': [{'boxes': tensor([[138, 138, 161, 161]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[138, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[138, 138, 161, 161]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[138, 138, 161, 161]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3924-bbox-1531263977.jpg', 'targets_list': [{'boxes': tensor([[ 89, 100, 211, 200]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 90,  84, 211, 221]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 89, 100, 211, 200]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 90,  84, 211, 221]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105416.jpg', 'targets_list': [{'boxes': tensor([[102,  99, 197, 200]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[103, 104, 199, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[102,  99, 197, 200]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[103, 104, 199, 189]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796973.jpg', 'targets_list': [{'boxes': tensor([[144, 142, 155, 157]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[130, 126, 162, 160]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[144, 142, 155, 157]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[130, 126, 162, 160]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161557-bbox-1415718285.jpg', 'targets_list': [{'boxes': tensor([[129, 128, 170, 171]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 130, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[129, 128, 170, 171]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 130, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161627-bbox-1415718401.jpg', 'targets_list': [{'boxes': tensor([[131, 132, 169, 168]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[134, 134, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[131, 132, 169, 168]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[134, 134, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1884-bbox-1519001513.jpg', 'targets_list': [{'boxes': tensor([[135, 121, 164, 179]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[133, 126, 166, 172]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[135, 121, 164, 179]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[133, 126, 166, 172]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585512.jpg', 'targets_list': [{'boxes': tensor([[128,  97, 171, 202]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[133, 119, 168, 170],
        [129, 119, 138, 170]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]}

targets: [{'boxes': tensor([[128,  97, 171, 202]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[133, 119, 168, 170],
        [129, 119, 138, 170]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533748.jpg', 'targets_list': [{'boxes': tensor([[136, 129, 164, 170]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[122, 129, 173, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[136, 129, 164, 170]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[122, 129, 173, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785688.jpg', 'targets_list': [{'boxes': tensor([[130, 128, 169, 172]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[129, 131, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[130, 128, 169, 172]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[129, 131, 170, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671366.jpg', 'targets_list': [{'boxes': tensor([[ 94, 112, 205, 188]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[103, 119, 191, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 94, 112, 205, 188]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[103, 119, 191, 178]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013911.jpg', 'targets_list': [{'boxes': tensor([[125, 120, 175, 179]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[125, 123, 176, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[125, 120, 175, 179]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[125, 123, 176, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930928.jpg', 'targets_list': [{'boxes': tensor([[ 79, 101, 221, 199]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 72,  82, 224, 220]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 79, 101, 221, 199]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 72,  82, 224, 220]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014508.jpg', 'targets_list': [{'boxes': tensor([[127, 125, 173, 174]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[127, 127, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[127, 125, 173, 174]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[127, 127, 172, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527552588.jpg', 'targets_list': [{'boxes': tensor([[112, 104, 188, 196]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[106, 103, 196, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[112, 104, 188, 196]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[106, 103, 196, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527535106.jpg', 'targets_list': [{'boxes': tensor([[124, 120, 175, 179]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 125, 170, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[124, 120, 175, 179]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 125, 170, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673161.jpg', 'targets_list': [{'boxes': tensor([[100, 124, 199, 175]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[112, 123, 181, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[100, 124, 199, 175]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[112, 123, 181, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_110955-bbox-1416788116.jpg', 'targets_list': [{'boxes': tensor([[136, 134, 164, 166]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[134, 134, 164, 164]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 134, 164, 166]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[134, 134, 164, 164]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_091623-bbox-1500499877.jpg', 'targets_list': [{'boxes': tensor([[115, 122, 184, 178]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[110, 107, 201, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[115, 122, 184, 178]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[110, 107, 201, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015016.jpg', 'targets_list': [{'boxes': tensor([[132, 128, 168, 172]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[130, 129, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[132, 128, 168, 172]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[130, 129, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3633-bbox-1506586888.jpg', 'targets_list': [{'boxes': tensor([[ 86,  93, 213, 206]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 92,  90, 208, 208]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 86,  93, 213, 206]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 92,  90, 208, 208]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796981.jpg', 'targets_list': [{'boxes': tensor([[138, 140, 161, 160]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[134, 135, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[138, 140, 161, 160]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[134, 135, 165, 166]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001601.jpg', 'targets_list': [{'boxes': tensor([[125, 127, 175, 173]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[100, 110, 200, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[125, 127, 175, 173]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[100, 110, 200, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595382.jpg', 'targets_list': [{'boxes': tensor([[ 52,  46, 247, 254]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 57,  51, 232, 240]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 52,  46, 247, 254]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 57,  51, 232, 240]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776111.jpg', 'targets_list': [{'boxes': tensor([[120, 120, 179, 179]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[118, 123, 177, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[120, 120, 179, 179]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[118, 123, 177, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_142609-bbox-1418602379.jpg', 'targets_list': [{'boxes': tensor([[127, 125, 172, 175]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[126, 127, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[127, 125, 172, 175]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[126, 127, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104711.jpg', 'targets_list': [{'boxes': tensor([[112, 101, 188, 198]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[115, 107, 188, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[112, 101, 188, 198]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[115, 107, 188, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776082.jpg', 'targets_list': [{'boxes': tensor([[132, 131, 168, 168]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 134, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[132, 131, 168, 168]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 134, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092113-bbox-1418087508.jpg', 'targets_list': [{'boxes': tensor([[131, 130, 168, 170]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 131, 168, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[131, 130, 168, 170]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 131, 168, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478041.jpg', 'targets_list': [{'boxes': tensor([[130, 128, 170, 171]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 125, 170, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[130, 128, 170, 171]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 125, 170, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530732963.jpg', 'targets_list': [{'boxes': tensor([[116, 106, 183, 194]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[111,  94, 180, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[116, 106, 183, 194]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[111,  94, 180, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434743.jpg', 'targets_list': [{'boxes': tensor([[ 98, 126, 202, 173]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 96, 114, 209, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 98, 126, 202, 173]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 96, 114, 209, 188]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227905.jpg', 'targets_list': [{'boxes': tensor([[128, 120, 172, 180]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[111, 111, 183, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[128, 120, 172, 180]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[111, 111, 183, 184]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1876-bbox-1518941263.jpg', 'targets_list': [{'boxes': tensor([[ 82,  63, 218, 236]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 84,  64, 211, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 82,  63, 218, 236]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 84,  64, 211, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2797-bbox-1531447964.jpg', 'targets_list': [{'boxes': tensor([[136, 130, 163, 170]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[138, 137, 161, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 130, 163, 170]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[138, 137, 161, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865796.jpg', 'targets_list': [{'boxes': tensor([[ 89,  94, 211, 206]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 75,  88, 216, 207]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 89,  94, 211, 206]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 75,  88, 216, 207]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540462.jpg', 'targets_list': [{'boxes': tensor([[ 83, 119, 216, 181]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[130, 126, 192, 161]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 83, 119, 216, 181]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[130, 126, 192, 161]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013964.jpg', 'targets_list': [{'boxes': tensor([[119, 118, 180, 181]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[119, 115, 180, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[119, 118, 180, 181]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[119, 115, 180, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434937.jpg', 'targets_list': [{'boxes': tensor([[108, 120, 191, 180]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[103, 104, 199, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[108, 120, 191, 180]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[103, 104, 199, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673175.jpg', 'targets_list': [{'boxes': tensor([[ 86,  94, 214, 206]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 123, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 86,  94, 214, 206]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 123, 174, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675457.jpg', 'targets_list': [{'boxes': tensor([[122, 122, 177, 177]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[125, 126, 170, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[122, 122, 177, 177]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[125, 126, 170, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4533-bbox-1533854132.jpg', 'targets_list': [{'boxes': tensor([[127, 122, 173, 177]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[126, 126, 174, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[127, 122, 173, 177]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[126, 126, 174, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096981.jpg', 'targets_list': [{'boxes': tensor([[118, 117, 181, 182]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[123, 123, 176, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[118, 117, 181, 182]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[123, 123, 176, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671365.jpg', 'targets_list': [{'boxes': tensor([[ 66,  81, 234, 218]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 64,  80, 235, 232]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 66,  81, 234, 218]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 64,  80, 235, 232]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104764.jpg', 'targets_list': [{'boxes': tensor([[123, 112, 177, 188]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[123, 119, 174, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[123, 112, 177, 188]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[123, 119, 174, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1501095756.jpg', 'targets_list': [{'boxes': tensor([[122, 114, 177, 186]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[115, 115, 178, 188]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[122, 114, 177, 186]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[115, 115, 178, 188]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012710.jpg', 'targets_list': [{'boxes': tensor([[136, 137, 164, 162]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 135, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 137, 164, 162]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 135, 162, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445786.jpg', 'targets_list': [{'boxes': tensor([[198, 142, 216, 158]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[198, 142, 216, 158]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796998.jpg', 'targets_list': [{'boxes': tensor([[139, 136, 161, 163]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[134, 131, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[139, 136, 161, 163]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[134, 131, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014515.jpg', 'targets_list': [{'boxes': tensor([[128, 126, 172, 173]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[126, 126, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[128, 126, 172, 173]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[126, 126, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348206.jpg', 'targets_list': [{'boxes': tensor([[122, 126, 178, 173]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[123, 126, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[122, 126, 178, 173]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[123, 126, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102981.jpg', 'targets_list': [{'boxes': tensor([[136, 138, 163, 161]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[145, 145, 156, 157]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 138, 163, 161]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[145, 145, 156, 157]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999517.jpg', 'targets_list': [{'boxes': tensor([[ 78,  92, 222, 207]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 70,  64, 233, 237]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 78,  92, 222, 207]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 70,  64, 233, 237]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105412.jpg', 'targets_list': [{'boxes': tensor([[ 88, 108, 212, 191]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 91, 106, 201, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 88, 108, 212, 191]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 91, 106, 201, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1887-bbox-1519014887.jpg', 'targets_list': [{'boxes': tensor([[130, 101, 170, 199]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[116,  88, 185, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[130, 101, 170, 199]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[116,  88, 185, 201]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445788.jpg', 'targets_list': [{'boxes': tensor([[103, 139, 131, 160]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[103, 139, 131, 160]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524840.jpg', 'targets_list': [{'boxes': tensor([[135, 115, 165, 185]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[126, 116, 180, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[135, 115, 165, 185]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[126, 116, 180, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748101.jpg', 'targets_list': [{'boxes': tensor([[ 94, 102, 206, 198]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[102, 106, 193, 193],
        [102, 106, 170, 150]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]}

targets: [{'boxes': tensor([[ 94, 102, 206, 198]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[102, 106, 193, 193],
        [102, 106, 170, 150]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610358.jpg', 'targets_list': [{'boxes': tensor([[101, 119, 199, 180]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[102, 115, 203, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[101, 119, 199, 180]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[102, 115, 203, 191]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014513.jpg', 'targets_list': [{'boxes': tensor([[149, 117, 210, 183]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[131, 122, 187, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[149, 117, 210, 183]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[131, 122, 187, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078060.jpg', 'targets_list': [{'boxes': tensor([[118,  86, 182, 213]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[110,  88, 192, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[118,  86, 182, 213]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[110,  88, 192, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012708.jpg', 'targets_list': [{'boxes': tensor([[136, 137, 164, 163]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[138, 138, 161, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[136, 137, 164, 163]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[138, 138, 161, 162]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_111804-bbox-1416831263.jpg', 'targets_list': [{'boxes': tensor([[139, 138, 161, 162]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[139, 141, 158, 158]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[139, 138, 161, 162]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[139, 141, 158, 158]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675952.jpg', 'targets_list': [{'boxes': tensor([[118, 119, 181, 180]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[123, 125, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[118, 119, 181, 180]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[123, 125, 174, 172]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610347.jpg', 'targets_list': [{'boxes': tensor([[110, 111, 190, 188]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[110, 103, 188, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[110, 111, 190, 188]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[110, 103, 188, 192]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332497.jpg', 'targets_list': [{'boxes': tensor([[110,  85, 189, 215]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[102,  88, 192, 216]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[110,  85, 189, 215]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[102,  88, 192, 216]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527532582.jpg', 'targets_list': [{'boxes': tensor([[119, 118, 180, 181]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 119, 172, 164],
        [126, 131, 137, 156]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]}

targets: [{'boxes': tensor([[119, 118, 180, 181]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 119, 172, 164],
        [126, 131, 137, 156]]), 'scores': tensor([1, 1]), 'labels': tensor([3, 5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679973.jpg', 'targets_list': [{'boxes': tensor([[ 84,  88, 216, 212]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[110, 116, 193, 181]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 84,  88, 216, 212]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[110, 116, 193, 181]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673155.jpg', 'targets_list': [{'boxes': tensor([[113, 119, 187, 180]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 119, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[113, 119, 187, 180]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 119, 172, 173]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879130.jpg', 'targets_list': [{'boxes': tensor([[131, 134, 169, 166]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[129, 130, 170, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[131, 134, 169, 166]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[129, 130, 170, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104759.jpg', 'targets_list': [{'boxes': tensor([[109, 109, 190, 190]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[103, 110, 192, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[109, 109, 190, 190]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[103, 110, 192, 184]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348202.jpg', 'targets_list': [{'boxes': tensor([[127, 122, 173, 177]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[127, 126, 173, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[127, 122, 173, 177]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[127, 126, 173, 174]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947781.jpg', 'targets_list': [{'boxes': tensor([[ 80,  79, 219, 221]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 91,  91, 205, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 80,  79, 219, 221]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 91,  91, 205, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2423-bbox-1501245589.jpg', 'targets_list': [{'boxes': tensor([[ 95, 110, 205, 190]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 94,  87, 211, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 95, 110, 205, 190]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 94,  87, 211, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013876.jpg', 'targets_list': [{'boxes': tensor([[127, 128, 173, 171]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[130, 131, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[127, 128, 173, 171]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[130, 131, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947965.jpg', 'targets_list': [{'boxes': tensor([[ 81, 103, 219, 196]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 74,  63, 236, 244]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 81, 103, 219, 196]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 74,  63, 236, 244]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_164849-bbox-1530660763.jpg', 'targets_list': [{'boxes': tensor([[113, 112, 187, 187]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[116, 112, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[113, 112, 187, 187]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[116, 112, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434529.jpg', 'targets_list': [{'boxes': tensor([[117, 121, 183, 178]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 123, 180, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[117, 121, 183, 178]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 123, 180, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332542.jpg', 'targets_list': [{'boxes': tensor([[ 97, 103, 203, 196]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 99,  96, 193, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 97, 103, 203, 196]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 99,  96, 193, 197]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001609.jpg', 'targets_list': [{'boxes': tensor([[127, 121, 172, 179]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[121, 122, 172, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[127, 121, 172, 179]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[121, 122, 172, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141515.jpg', 'targets_list': [{'boxes': tensor([[119, 122, 181, 178]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 121, 180, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[119, 122, 181, 178]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 121, 180, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102982.jpg', 'targets_list': [{'boxes': tensor([[131, 130, 168, 170]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[131, 134, 164, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[131, 130, 168, 170]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[131, 134, 164, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015018.jpg', 'targets_list': [{'boxes': tensor([[138, 133, 162, 166]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[141, 139, 160, 158]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[138, 133, 162, 166]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[141, 139, 160, 158]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211972.jpg', 'targets_list': [{'boxes': tensor([[123, 105, 177, 194]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[116,  95, 185, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[123, 105, 177, 194]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[116,  95, 185, 199]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675954.jpg', 'targets_list': [{'boxes': tensor([[127, 119, 172, 181]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[123, 119, 173, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[127, 119, 172, 181]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[123, 119, 173, 177]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818817.jpg', 'targets_list': [{'boxes': tensor([[128, 123, 172, 177]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[123, 121, 178, 177]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[128, 123, 172, 177]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[123, 121, 178, 177]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012700.jpg', 'targets_list': [{'boxes': tensor([[118, 119, 181, 180]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[115, 115, 183, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[118, 119, 181, 180]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[115, 115, 183, 183]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865815.jpg', 'targets_list': [{'boxes': tensor([[ 99,  86, 201, 213]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 92,  92, 211, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 99,  86, 201, 213]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 92,  92, 211, 204]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012712.jpg', 'targets_list': [{'boxes': tensor([[138, 138, 162, 161]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[137, 137, 161, 160]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[138, 138, 162, 161]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[137, 137, 161, 160]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212067.jpg', 'targets_list': [{'boxes': tensor([[114,  93, 186, 207]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 78,  82, 224, 216]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[114,  93, 186, 207]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 78,  82, 224, 216]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865789.jpg', 'targets_list': [{'boxes': tensor([[114, 119, 185, 180]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[122, 130, 176, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[114, 119, 185, 180]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[122, 130, 176, 178]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524312.jpg', 'targets_list': [{'boxes': tensor([[126, 124, 173, 176]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 123, 173, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[126, 124, 173, 176]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 123, 173, 174]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102976.jpg', 'targets_list': [{'boxes': tensor([[123, 126, 177, 173]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 133, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[123, 126, 177, 173]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 133, 169, 170]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_091623-bbox-1500499878.jpg', 'targets_list': [{'boxes': tensor([[124, 129, 175, 171]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 131, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[124, 129, 175, 171]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 131, 178, 180]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797235.jpg', 'targets_list': [{'boxes': tensor([[134, 138, 165, 162]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[134, 138, 165, 162]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652324.jpg', 'targets_list': [{'boxes': tensor([[ 89,  88, 211, 212]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[ 92,  87, 208, 212]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[ 89,  88, 211, 212]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[ 92,  87, 208, 212]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-06-02-vianopolis-go-20230602_135136-bbox-1407347295.jpg', 'targets_list': [{'boxes': tensor([[ 71,  82, 228, 218]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[ 87,  91, 220, 211]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[ 71,  82, 228, 218]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[ 87,  91, 220, 211]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013916.jpg', 'targets_list': [{'boxes': tensor([[120, 121, 179, 178]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[121, 121, 180, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[120, 121, 179, 178]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[121, 121, 180, 178]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030594.jpg', 'targets_list': [{'boxes': tensor([[122, 125, 178, 174]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[107, 118, 195, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[122, 125, 178, 174]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[107, 118, 195, 176]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679955.jpg', 'targets_list': [{'boxes': tensor([[100,  92, 200, 207]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[102,  98, 195, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[100,  92, 200, 207]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[102,  98, 195, 197]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533736.jpg', 'targets_list': [{'boxes': tensor([[118, 122, 182, 178]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[121, 123, 177, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[118, 122, 182, 178]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[121, 123, 177, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104722.jpg', 'targets_list': [{'boxes': tensor([[127, 128, 173, 171]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[130, 130, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[127, 128, 173, 171]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[130, 130, 169, 169]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478002.jpg', 'targets_list': [{'boxes': tensor([[127, 126, 172, 174]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]}

targets: [{'boxes': tensor([[127, 126, 172, 174]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([]), 'scores': tensor([]), 'labels': tensor([])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434960.jpg', 'targets_list': [{'boxes': tensor([[128, 125, 172, 174]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[125, 126, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[128, 125, 172, 174]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[125, 126, 172, 170]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675461.jpg', 'targets_list': [{'boxes': tensor([[117, 129, 182, 171]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[119, 122, 177, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[117, 129, 182, 171]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[119, 122, 177, 176]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947937.jpg', 'targets_list': [{'boxes': tensor([[ 97, 114, 203, 186]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 96,  98, 203, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 97, 114, 203, 186]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 96,  98, 203, 200]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999537.jpg', 'targets_list': [{'boxes': tensor([[ 91,  64, 209, 235]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 86,  83, 200, 223]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 91,  64, 209, 235]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 86,  83, 200, 223]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679968.jpg', 'targets_list': [{'boxes': tensor([[ 96,  90, 203, 210]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 84,  79, 216, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[ 96,  90, 203, 210]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 84,  79, 216, 224]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104739.jpg', 'targets_list': [{'boxes': tensor([[120, 112, 179, 187]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[127, 122, 176, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[120, 112, 179, 187]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[127, 122, 176, 183]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013912.jpg', 'targets_list': [{'boxes': tensor([[138, 140, 161, 160]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[143, 146, 154, 157]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[138, 140, 161, 160]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[143, 146, 154, 157]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434558.jpg', 'targets_list': [{'boxes': tensor([[116, 113, 184, 186]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[118, 118, 184, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[116, 113, 184, 186]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[118, 118, 184, 181]]), 'scores': tensor([1]), 'labels': tensor([3])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501097029.jpg', 'targets_list': [{'boxes': tensor([[108, 101, 192, 198]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[104, 107, 201, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[108, 101, 192, 198]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[104, 107, 201, 203]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671369.jpg', 'targets_list': [{'boxes': tensor([[102, 118, 197, 182]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 99, 121, 188, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[102, 118, 197, 182]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 99, 121, 188, 185]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775291.jpg', 'targets_list': [{'boxes': tensor([[132, 134, 167, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[131, 131, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[132, 134, 167, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[131, 131, 166, 166]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013962.jpg', 'targets_list': [{'boxes': tensor([[132, 134, 168, 165]]), 'labels': tensor([1])}], 'preds_list': [{'boxes': tensor([[133, 135, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[132, 134, 168, 165]]), 'labels': tensor([1])}]
preds: [{'boxes': tensor([[133, 135, 165, 165]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530731203.jpg', 'targets_list': [{'boxes': tensor([[107, 104, 193, 195]]), 'labels': tensor([5])}], 'preds_list': [{'boxes': tensor([[ 95,  95, 197, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]}

targets: [{'boxes': tensor([[107, 104, 193, 195]]), 'labels': tensor([5])}]
preds: [{'boxes': tensor([[ 95,  95, 197, 212]]), 'scores': tensor([1]), 'labels': tensor([5])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434806.jpg', 'targets_list': [{'boxes': tensor([[116, 118, 183, 182]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[112, 114, 187, 181]]), 'scores': tensor([1]), 'labels': tensor([1])}]}

targets: [{'boxes': tensor([[116, 118, 183, 182]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[112, 114, 187, 181]]), 'scores': tensor([1]), 'labels': tensor([1])}]
 inferenced_image: {'image_name': 'ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434769.jpg', 'targets_list': [{'boxes': tensor([[110, 105, 189, 195]]), 'labels': tensor([3])}], 'preds_list': [{'boxes': tensor([[112, 103, 187, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]}

targets: [{'boxes': tensor([[110, 105, 189, 195]]), 'labels': tensor([3])}]
preds: [{'boxes': tensor([[112, 103, 187, 195]]), 'scores': tensor([1]), 'labels': tensor([3])}]
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785691_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1500526739_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3979-bbox-1533656590_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797254_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212058_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533752_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434568_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332475_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135678_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947686_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748029_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610356_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797053_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211850_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796994_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818813_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930897_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096986_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-02-fazenda-vs-pivo-06-IMG_2875-bbox-1529999100_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212091_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-03-pivo-03-20230930_123113-bbox-1429245310_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604248_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161557-bbox-1415718287_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775271_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776103_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533791_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533791_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013908_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160508-bbox-1411007689_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120312-bbox-1533675660_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4519-bbox-1533833204_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675469_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679961_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451613_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2530-bbox-1505679998_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675467_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2528-bbox-1505667180_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078097_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1804-bbox-1524227328_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930918_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743250_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013917_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092113-bbox-1418087509_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2798-bbox-1531448008_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445789_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610377_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785699_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_162248-bbox-1416067564_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604258_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_163521-bbox-1529526422_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_135337-bbox-1407347421_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015009_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105404_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434579_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014504_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947677_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776168_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524765_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001608_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2477-bbox-1503748285_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1897-bbox-1519483072_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527536645_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112354-bbox-1417775833_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012704_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524443_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947725_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-02-fazenda-vs-pivo-06-IMG_2875-bbox-1529999102_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478590_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748053_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014510_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348197_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3928-bbox-1531429137_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227985_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652326_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_111804-bbox-1416831265_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2482-bbox-1504140817_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001614_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013963_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013875_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451492_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2562-bbox-1506386836_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161627-bbox-1415718393_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524795_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102985_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078086_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527544133_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012707_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_162248-bbox-1416067575_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500499785_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604276_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930921_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652330_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_135136-bbox-1407347318_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135702_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743234_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947984_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500495896_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434714_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775298_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818829_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818829_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530730668_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797021_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775232_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1967-bbox-1500168559_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679959_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104752_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530725274_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104720_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096983_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530731602_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999543_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527535109_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2478-bbox-1503748392_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_110955-bbox-1416788230_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104769_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105411_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3633-bbox-1506586882_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604268_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013907_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434827_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785712_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879143_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_163521-bbox-1529526130_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1967-bbox-1500168166_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999521_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540438_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104735_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1799-bbox-1524135726_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3930-bbox-1531429402_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_164849-bbox-1530658464_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2579-bbox-1499560953_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585146_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105427_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_1913-bbox-1518743231_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212093_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534091011_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078092_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930912_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2475-bbox-1503748166_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1884-bbox-1519001508_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999530_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112354-bbox-1417775811_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2530-bbox-1505679995_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3938-bbox-1531451419_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096987_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015014_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2482-bbox-1504140857_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999519_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013909_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675464_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_1971-bbox-1500499770_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1887-bbox-1519014865_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141463_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775492_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999544_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2452-bbox-1503652385_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534090915_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879141_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748045_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539856_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030577_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947644_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434586_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211899_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030606_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030606_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095137-bbox-1500962989_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748040_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539646_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102979_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227961_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1876-bbox-1518941256_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604272_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_3901-bbox-1533822128_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161634-bbox-1415718444_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2598-bbox-1499561022_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595384_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014505_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533753_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527539647_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434612_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671387_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105414_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604252_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161634-bbox-1415718433_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524305_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1519910868_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673162_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2766-bbox-1530054833_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533759_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595385_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4532-bbox-1533854039_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604281_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_150452-bbox-1418604281_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_094448-bbox-1418427497_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227933_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2562-bbox-1506386819_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141461_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675948_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530737130_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_3901-bbox-1533822142_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947869_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540435_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013877_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1534090997_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092252-bbox-1418298951_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332531_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120314-bbox-1533675703_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014507_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3924-bbox-1531263977_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105416_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796973_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161557-bbox-1415718285_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_161627-bbox-1415718401_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1884-bbox-1519001513_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585512_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3870-bbox-1527585512_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533748_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-ipameri-go-fazenda-jolart-20230706_160026-bbox-1410785688_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671366_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013911_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1836-bbox-1526930928_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014508_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527552588_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527535106_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673161_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_110955-bbox-1416788116_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_091623-bbox-1500499877_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015016_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3633-bbox-1506586888_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796981_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001601_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3653-bbox-1506595382_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776111_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_142609-bbox-1418602379_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104711_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112433-bbox-1417776082_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092113-bbox-1418087508_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478041_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530732963_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434743_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1813-bbox-1524227905_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1876-bbox-1518941263_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2797-bbox-1531447964_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865796_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527540462_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013964_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434937_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673175_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675457_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4533-bbox-1533854132_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501096981_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671365_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104764_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092430-bbox-1501095756_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012710_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445786_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518796998_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014515_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348206_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102981_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999517_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2415-bbox-1501105412_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1887-bbox-1519014887_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-03-fazenda-sao-pedro-pivo-07-IMG_2791-bbox-1531445788_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524840_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748101_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2473-bbox-1503748101_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610358_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4503-bbox-1533014513_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_20230907_145532-bbox-1527078060_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012708_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_111804-bbox-1416831263_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675952_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3665-bbox-1506610347_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332497_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527532582_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3868-bbox-1527532582_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679973_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_120431-bbox-1533673155_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-01-fazenda-vs-pivo-05-IMG_2620-bbox-1529879130_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104759_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1407348202_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1858-bbox-1526947781_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2423-bbox-1501245589_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013876_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947965_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_20230907_164849-bbox-1530660763_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434529_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2434-bbox-1501332542_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1885-bbox-1519001609_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2487-bbox-1504141515_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102982_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-20230930_115113-bbox-1533015018_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528211972_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_120511-bbox-1533675954_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_140024-bbox-1418818817_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012700_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865815_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_20230930_104430-bbox-1533012712_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3886-bbox-1528212067_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_4557-bbox-1533865789_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_20230907_113344-bbox-1519524312_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-agreste-20230706_092231-bbox-1418102976_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_091623-bbox-1500499878_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-02-IMG_3758-bbox-1518797235_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2448-bbox-1503652324_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-06-02-vianopolis-go-20230602_135136-bbox-1407347295_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013916_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1870-bbox-1527030594_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679955_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_092611-bbox-1500533736_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104722_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-03-IMG_1893-bbox-1519478002_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/undetected-fn
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434960_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-02-pivo-02-IMG_20230930_115522-bbox-1533675461_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_1859-bbox-1526947937_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3953-bbox-1532999537_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_2529-bbox-1505679968_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_101245-bbox-1501104739_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013912_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/err-pred-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3828-bbox-1527434558_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_20230907_095902-bbox-1501097029_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-01-IMG_3692-bbox-1506671369_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-07-06-cristalina-go-fazenda-cristal-20230706_112335-bbox-1417775291_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-30-turvelandia-go-grupo-santa-fe-01-fazenda-sao-pedro-pivo-01-IMG_4494-bbox-1533013962_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-08-turvelandia-go-grupo-santa-fe-04-fazenda-sao-pedro-pivo-08-IMG_3921-bbox-1530731203_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434806_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-fp
metrics rubens - tested_folder: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - filename: ds-2023-09-07-santa-helena-de-goias-go-fazenda-sete-ilhas-pivo-04-IMG_3830-bbox-1527434769_predicted.jpg
metrics rubens - input_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image
metrics rubens - output_path: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/tested-image/target-tp
full_confusion_matrix: 
[[  0.   0.   0.   0.   0.   0.   0.]
 [  0.  79.   0.   1.   0.   0.   4.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   3.   0.  96.   0.   6.  11.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   5.   0. 112.   5.]
 [  0.   1.   0.   6.   0.   1.   0.]]
self.full_confusion_matrix: [[  0.   0.   0.   0.   0.   0.   0.]
 [  0.  79.   0.   1.   0.   0.   4.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   3.   0.  96.   0.   6.  11.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   5.   0. 112.   5.]
 [  0.   1.   0.   6.   0.   1.   0.]]
cm_tn: [[ 79.   0.   1.   0.   0.   4.]
 [  0.   0.   0.   0.   0.   0.]
 [  3.   0.  96.   0.   6.  11.]
 [  0.   0.   0.   0.   0.   0.]
 [  0.   0.   5.   0. 112.   5.]]
number_of_classes: 5
compute_metrics_from_confusion_matrix - i: 0 >> number_of_classes: 5
compute_metrics_from_confusion_matrix - i: 1 >> number_of_classes: 5
compute_metrics_from_confusion_matrix - i: 2 >> number_of_classes: 5
compute_metrics_from_confusion_matrix - i: 3 >> number_of_classes: 5
compute_metrics_from_confusion_matrix - i: 4 >> number_of_classes: 5

FULL CONFUSION MATRIX
---------------------

[[  0.   0.   0.   0.   0.   0.   0.]
 [  0.  79.   0.   1.   0.   0.   4.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   3.   0.  96.   0.   6.  11.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   5.   0. 112.   5.]
 [  0.   1.   0.   6.   0.   1.   0.]]

CONFUSION MATRIX
---------------------------

[[ 79.   0.   1.   0.   0.]
 [  0.   0.   0.   0.   0.]
 [  3.   0.  96.   0.   6.]
 [  0.   0.   0.   0.   0.]
 [  0.   0.   5.   0. 112.]]

SUMMARY OF CONFUSION MATRIX
---------------------------

Total number of images               : 323
Bounding boxes target                : 323
Bounding boxes predicted             : 322
Bounding boxes predicted with target : 302
Number of ghost preditions           : 20
Number of undetected objects         : 8

inference_metric.to_string(): 
Metrics

len(self.inferenced_images): 323

inference_metric.full_confusion_matrix: [[  0.   0.   0.   0.   0.   0.   0.]
 [  0.  79.   0.   1.   0.   0.   4.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   3.   0.  96.   0.   6.  11.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   5.   0. 112.   5.]
 [  0.   1.   0.   6.   0.   1.   0.]]
path_and_filename: /home/lovelace/proj/proj939/rubenscp/research/white-mold-applications/model/predictions/TU_WhiteMold224/TU_pretrain_R50-ViT-B_16_skip3_epo50_bs24_224/metrics/TransUNet_001_confusion_matrix_full.png
title: Full Confusion Matrix - Model: TransUNet   # images:323
Confidence threshold: 0   IoU threshold: 0.3   Non-maximum Supression: 0
format: .0f
x_labels_names: ['__background__', 'Apothecium', 'Imature Sclerotium', 'Mature Sclerotium', 'White Mold', 'Imature Sclerotium and White Mold', 'Incorrect predictions']
y_labels_names: ['__background__', 'Apothecium', 'Imature Sclerotium', 'Mature Sclerotium', 'White Mold', 'Imature Sclerotium and White Mold', 'Undetected objects']
column_names: ['' '__background__' 'Apothecium' 'Imature Sclerotium' 'Mature Sclerotium'
 'White Mold' 'Imature Sclerotium and White Mold' 'Incorrect predictions']
confusion_matrix: [[  0.   0.   0.   0.   0.   0.   0.]
 [  0.  79.   0.   1.   0.   0.   4.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   3.   0.  96.   0.   6.  11.]
 [  0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   5.   0. 112.   5.]
 [  0.   1.   0.   6.   0.   1.   0.]]
 tp_per_classes: [ 79.   0.  96.   0. 112.]
item: [0. 0. 0. 0. 0. 0. 0.]
item: [ 0. 79.  0.  1.  0.  0.  4.]
item: [0. 0. 0. 0. 0. 0. 0.]
item: [ 0.  3.  0. 96.  0.  6. 11.]
item: [0. 0. 0. 0. 0. 0. 0.]
item: [  0.   0.   0.   5.   0. 112.   5.]
item: [0. 1. 0. 6. 0. 1. 0.]
rubens
len(tp_per_classes): 5
fp_per_classes: [ 5.  0. 20.  0. 10.]
fn_per_classes: [1. 0. 6. 0. 1.]
tp_per_classes: [ 79.   0.  96.   0. 112.]
x_labels_names: ['__background__', 'Apothecium', 'Imature Sclerotium', 'Mature Sclerotium', 'White Mold', 'Imature Sclerotium and White Mold', 'Incorrect predictions']
classes: ['Apothecium', 'Imature Sclerotium', 'Mature Sclerotium', 'White Mold', 'Imature Sclerotium and White Mold', 'Incorrect predictions']
i: 0
i: 1
i: 2
i: 3
i: 4
list: [['__background__', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], ['Apothecium', '0.0', '79.0', '0.0', '1.0', '0.0', '0.0', '4.0'], ['Imature Sclerotium', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], ['Mature Sclerotium', '0.0', '3.0', '0.0', '96.0', '0.0', '6.0', '11.0'], ['White Mold', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], ['Imature Sclerotium and White Mold', '0.0', '0.0', '0.0', '5.0', '0.0', '112.0', '5.0'], ['Undetected objects', '0.0', '1.0', '0.0', '6.0', '0.0', '1.0', '0.0'], '', ['', 'TP', 'FP', 'FN', 'TN'], ['Apothecium', 79.0, 5.0, 1.0, 235.0], ['Imature Sclerotium', 0.0, 0.0, 0.0, 322.0], ['Mature Sclerotium', 96.0, 20.0, 6.0, 200.0], ['White Mold', 0.0, 0.0, 0.0, 322.0], ['Imature Sclerotium and White Mold', 112.0, 10.0, 1.0, 194.0]]
column_names: ['' '__background__' 'Apothecium' 'Imature Sclerotium' 'Mature Sclerotium'
 'White Mold' 'Imature Sclerotium and White Mold' 'Incorrect predictions']
confusion_matrix: [[0.         0.         0.         0.         0.         0.
  0.        ]
 [0.         0.95180723 0.         0.00925926 0.         0.
  0.2       ]
 [0.         0.         0.         0.         0.         0.
  0.        ]
 [0.         0.03614458 0.         0.88888889 0.         0.05042017
  0.55      ]
 [0.         0.         0.         0.         0.         0.
  0.        ]
 [0.         0.         0.         0.0462963  0.         0.94117647
  0.25      ]
 [0.         0.01204819 0.         0.05555556 0.         0.00840336
  0.        ]]
 tp_per_classes: [ 79.   0.  96.   0. 112.]
item: [0. 0. 0. 0. 0. 0. 0.]
item: [0.         0.95180723 0.         0.00925926 0.         0.
 0.2       ]
item: [0. 0. 0. 0. 0. 0. 0.]
item: [0.         0.03614458 0.         0.88888889 0.         0.05042017
 0.55      ]
item: [0. 0. 0. 0. 0. 0. 0.]
item: [0.         0.         0.         0.0462963  0.         0.94117647
 0.25      ]
item: [0.         0.01204819 0.         0.05555556 0.         0.00840336
 0.        ]
rubens
len(tp_per_classes): 5
fp_per_classes: [ 5.  0. 20.  0. 10.]
fn_per_classes: [1. 0. 6. 0. 1.]
tp_per_classes: [ 79.   0.  96.   0. 112.]
x_labels_names: ['__background__', 'Apothecium', 'Imature Sclerotium', 'Mature Sclerotium', 'White Mold', 'Imature Sclerotium and White Mold', 'Incorrect predictions']
classes: ['Apothecium', 'Imature Sclerotium', 'Mature Sclerotium', 'White Mold', 'Imature Sclerotium and White Mold', 'Incorrect predictions']
i: 0
i: 1
i: 2
i: 3
i: 4
list: [['__background__', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], ['Apothecium', '0.0', '0.9518072289156626', '0.0', '0.009259259259259259', '0.0', '0.0', '0.2'], ['Imature Sclerotium', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], ['Mature Sclerotium', '0.0', '0.03614457831325301', '0.0', '0.8888888888888888', '0.0', '0.05042016806722689', '0.55'], ['White Mold', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0'], ['Imature Sclerotium and White Mold', '0.0', '0.0', '0.0', '0.046296296296296294', '0.0', '0.9411764705882353', '0.25'], ['Undetected objects', '0.0', '0.012048192771084338', '0.0', '0.05555555555555555', '0.0', '0.008403361344537815', '0.0'], '', ['', 'TP', 'FP', 'FN', 'TN'], ['Apothecium', 79.0, 5.0, 1.0, 235.0], ['Imature Sclerotium', 0.0, 0.0, 0.0, 322.0], ['Mature Sclerotium', 96.0, 20.0, 6.0, 200.0], ['White Mold', 0.0, 0.0, 0.0, 322.0], ['Imature Sclerotium and White Mold', 112.0, 10.0, 1.0, 194.0]]
self.tp_model: 287.0
self.fp_model: 35.0
self.tp_model: 287.0
self.fp_model: 35.0
self.tp_model: 287.0
self.fp_model: 35.0

['Metrics Results calculated by application', '']
['', '']
['Model', 'TransUNet']
['', '']
['Threshold', '0.00']
['IoU Threshold', '0.30']
['Non-Maximum Supression', '0.00']
['', '']
['TP / FP / FN / TN per Class', '']
['Class', 'TP', 'FP', 'FN', 'TN']
['Apothecium', '79', '5', '1', '235']
['Imature Sclerotium', '0', '0', '0', '322']
['Mature Sclerotium', '96', '20', '6', '200']
['White Mold', '0', '0', '0', '322']
['Imature Sclerotium and White Mold', '112', '10', '1', '194']
['Total', '287', '35', '8', '0']
['', '']
['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Dice']
['Apothecium', '0.98125000', '0.94047619', '0.98750000', '0.96341463', '0.96341463']
['Imature Sclerotium', '1.00000000', '0.00000000', '0.00000000', '0.00000000', '0.00000000']
['Mature Sclerotium', '0.91925466', '0.82758621', '0.94117647', '0.88073394', '0.88073394']
['White Mold', '1.00000000', '0.00000000', '0.00000000', '0.00000000', '0.00000000']
['Imature Sclerotium and White Mold', '0.96529968', '0.91803279', '0.99115044', '0.95319149', '0.95319149']
['Model Metrics', '0.00000000', '0.89130435', '0.97288136', '0.93030794', '0.93030794']
['', '']
['Metric measures', '']
['number_of_images', '323']
['number_of_bounding_boxes_target', '323']
['number_of_bounding_boxes_predicted', '322']
['number_of_bounding_boxes_predicted_with_target', '302']
['number_of_incorrect_predictions', '20']
['number_of_undetected_objects', '8']

Inference white mold dataset finished!
